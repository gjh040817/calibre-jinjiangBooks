
import re
import time
import random
import gzip
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from queue import Queue, Empty
from urllib.parse import urlparse, unquote, urlencode, parse_qs
from urllib.request import Request, urlopen
import ssl

# Calibre ç›¸å…³å¯¼å…¥
from calibre import random_user_agent
from calibre.ebooks.metadata import check_isbn
from calibre.ebooks.metadata.book.base import Metadata
from calibre.ebooks.metadata.sources.base import Source, Option
from lxml import etree



# HTML è½¬æ–‡æœ¬å·¥å…·ï¼ˆå¯é€‰ä¾èµ–ï¼‰
try:
    from html2text import html2text as _html2text
except Exception:
    _html2text = None


# å›½é™…åŒ–å‡½æ•°å›é€€æœºåˆ¶
# ç¡®ä¿ `_()` å‡½æ•°åœ¨é Calibre ç¯å¢ƒä¸‹ä¹Ÿå¯ç”¨ï¼Œé¿å…è¯­æ³•/ç¼–è¯‘æœŸé”™è¯¯
# åœ¨ Calibre ç¯å¢ƒä¸­ï¼Œ`_()` ç”¨äºç¿»è¯‘å­—ç¬¦ä¸²ï¼›åœ¨é Calibre ç¯å¢ƒä¸­ï¼Œç›´æ¥è¿”å›åŸå­—ç¬¦ä¸²
try:
    _
except NameError:
    def _(s):
        return s


def html_to_text(html: str) -> str:
    """
    å°† HTML å†…å®¹è½¬æ¢ä¸ºçº¯æ–‡æœ¬
    
    è½¬æ¢ç­–ç•¥ï¼š
    1. ä¼˜å…ˆä½¿ç”¨ html2text åº“ï¼ˆå¦‚æœå·²å®‰è£…ï¼‰ï¼Œèƒ½æ›´å¥½åœ°å¤„ç†å¤æ‚ HTML ç»“æ„
    2. å¦‚æœ html2text ä¸å¯ç”¨æˆ–è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•ï¼š
       - ç§»é™¤æ‰€æœ‰ HTML æ ‡ç­¾
       - å‹ç¼©å¤šä¸ªè¿ç»­ç©ºç™½å­—ç¬¦ä¸ºå•ä¸ªç©ºæ ¼
       - å»é™¤é¦–å°¾ç©ºç™½
    
    Args:
        html: å¾…è½¬æ¢çš„ HTML å­—ç¬¦ä¸²
        
    Returns:
        è½¬æ¢åçš„çº¯æ–‡æœ¬å­—ç¬¦ä¸²ï¼Œå¦‚æœè¾“å…¥ä¸ºç©ºåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    if not html:
        return ''
    # ä¼˜å…ˆä½¿ç”¨ html2text åº“è¿›è¡Œè½¬æ¢ï¼ˆå¤„ç†æ›´å®Œå–„ï¼‰
    if _html2text:
        try:
            return _html2text(html).strip()
        except Exception:
            pass
    # ç®€å•å›é€€æ–¹æ¡ˆï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤ HTML æ ‡ç­¾å¹¶å‹ç¼©ç©ºç™½å­—ç¬¦
    txt = re.sub(r'<[^>]+>', '', html)  # ç§»é™¤æ‰€æœ‰ HTML æ ‡ç­¾
    txt = re.sub(r'\s+', ' ', txt).strip()  # å°†å¤šä¸ªè¿ç»­ç©ºç™½å­—ç¬¦å‹ç¼©ä¸ºå•ä¸ªç©ºæ ¼
    return txt


def normalize_query(s: str) -> str:
    """
    æ¸…æ´—å’Œè§„èŒƒåŒ–æœç´¢å…³é”®è¯ï¼Œæé«˜æœç´¢åŒ¹é…ç‡
    
    å¤„ç†æ­¥éª¤ï¼š
    1. å…¨è§’å­—ç¬¦è½¬åŠè§’å­—ç¬¦ï¼ˆç»Ÿä¸€å­—ç¬¦å®½åº¦ï¼‰
    2. å»é™¤æ‹¬å·å†…æ³¨è®°
    3. ä¸­æ–‡æ ‡ç‚¹è½¬æ¢ä¸ºè‹±æ–‡æ ‡ç‚¹
    4. åˆ é™¤ä¸å¯è§å­—ç¬¦å’Œç‰¹æ®Šç¬¦å·ï¼ˆä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸­æ—¥éŸ©æ–‡å­—ã€å¸¸è§æ ‡ç‚¹ï¼‰
    5. åˆå¹¶å¤šä¸ªè¿ç»­ç©ºæ ¼ä¸ºå•ä¸ªç©ºæ ¼ï¼Œå»é™¤é¦–å°¾ç©ºç™½
    
    Args:
        s: åŸå§‹æœç´¢å…³é”®è¯

    Returns:
        æ¸…æ´—åçš„è§„èŒƒåŒ–å…³é”®è¯ï¼Œå¦‚æœè¾“å…¥ä¸ºç©ºåˆ™ç›´æ¥è¿”å›
    """
    if not s:
        return s
    
    # æ­¥éª¤1ï¼šå…¨è§’å­—ç¬¦è½¬åŠè§’å­—ç¬¦
    # å°†å…¨è§’ç©ºæ ¼ï¼ˆ0x3000ï¼‰å’Œå…¨è§’æ ‡ç‚¹ç¬¦å·ï¼ˆ0xFF01-0xFF5Eï¼‰è½¬æ¢ä¸ºå¯¹åº”çš„åŠè§’å­—ç¬¦
    def full2half(u):
        res = []
        for ch in u:
            code = ord(ch)
            if code == 0x3000:  # å…¨è§’ç©ºæ ¼
                res.append(' ')
            elif 0xFF01 <= code <= 0xFF5E:  # å…¨è§’æ ‡ç‚¹ç¬¦å·èŒƒå›´
                res.append(chr(code - 0xFEE0))  # è½¬æ¢ä¸ºå¯¹åº”çš„åŠè§’å­—ç¬¦
            else:
                res.append(ch)
        return ''.join(res)

    s = full2half(s)

    # æ­¥éª¤2ï¼šå»é™¤æ‹¬å·å†…çš„æ³¨è®°å†…å®¹ï¼ˆæ”¯æŒä¸­è‹±æ–‡æ‹¬å·ï¼‰
    # ç§»é™¤åœ†æ‹¬å·ã€æ–¹æ‹¬å·ã€ä¸­æ–‡æ‹¬å·ã€ä¸­æ–‡æ–¹æ‹¬å·å†…çš„æ‰€æœ‰å†…å®¹
    s = re.sub(r"\([^\)]*\)", '', s)  # è‹±æ–‡åœ†æ‹¬å·
    s = re.sub(r"\[[^\]]*\]", '', s)  # è‹±æ–‡æ–¹æ‹¬å·
    s = re.sub(r"ï¼ˆ[^ï¼‰]*ï¼‰", '', s)  # ä¸­æ–‡åœ†æ‹¬å·
    s = re.sub(r"ã€[^ã€‘]*ã€‘", '', s)  # ä¸­æ–‡æ–¹æ‹¬å·

    # æ­¥éª¤3ï¼šæ›¿æ¢ç‰¹æ®Šåˆ†éš”ç¬¦ä¸ºç©ºæ ¼ï¼Œä¸­æ–‡æ ‡ç‚¹è½¬æ¢ä¸ºè‹±æ–‡æ ‡ç‚¹
    # å°†å„ç§ä¸­ç‚¹ã€åˆ†éš”ç¬¦ç»Ÿä¸€æ›¿æ¢ä¸ºç©ºæ ¼
    s = s.replace('Â·', ' ').replace('â€¢', ' ').replace('ãƒ»', ' ').replace('\u2026', ' ')
    # ä¸­æ–‡æ ‡ç‚¹è½¬æ¢ä¸ºå¯¹åº”çš„è‹±æ–‡æ ‡ç‚¹
    s = s.replace('ï¼š', ':').replace('ã€‚', '.').replace('ï¼Œ', ',')

    # æ­¥éª¤4ï¼šåˆ é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œåªä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸­æ—¥éŸ©æ–‡å­—å’Œå¸¸è§æ ‡ç‚¹
    # \w: å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿
    # \u4e00-\u9fff: ä¸­æ—¥éŸ©ç»Ÿä¸€è¡¨æ„æ–‡å­—
    # \u3000-\u303F: CJK ç¬¦å·å’Œæ ‡ç‚¹
    # ä¿ç•™çš„æ ‡ç‚¹ï¼šè¿å­—ç¬¦(-)ã€ç‚¹(.)ã€å†’å·(:)ã€å•å¼•å·(')ã€é€—å·(,)ã€ç©ºæ ¼
    s = re.sub(r"[^\w\u4e00-\u9fff\u3000-\u303F\-\.:,' ]+", ' ', s)

    # æ­¥éª¤5ï¼šåˆå¹¶å¤šä¸ªè¿ç»­ç©ºæ ¼ä¸ºå•ä¸ªç©ºæ ¼ï¼Œå»é™¤é¦–å°¾ç©ºç™½
    s = re.sub(r"\s+", ' ', s).strip()
    return s


def generate_title_variations(cleaned_title: str):
    """
    åŸºäºæ¸…æ´—åçš„ä¹¦åç”Ÿæˆå¤šä¸ªæœç´¢å˜ä½“ï¼Œç”¨äºæé«˜æœç´¢åŒ¹é…ç‡
    
    å½“åŸå§‹æœç´¢æ— ç»“æœæ—¶ï¼Œé€šè¿‡ç”Ÿæˆå˜ä½“å¯ä»¥ï¼š
    1. å»é™¤å¸¸è§æ ‡æ³¨è¯ï¼ˆå¦‚"å®Œç»“"ã€"ç•ªå¤–"ç­‰ï¼‰ï¼Œè¿™äº›è¯å¯èƒ½å½±å“æœç´¢ç»“æœ
    2. æå–ä¹¦åä¸­çš„å…³é”®è¯ï¼ŒæŒ‰é•¿åº¦é™åºæ’åˆ—ï¼Œä¼˜å…ˆä½¿ç”¨è¾ƒé•¿çš„è¯
    
    å˜ä½“ç”Ÿæˆç­–ç•¥ï¼š
    - ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šå»é™¤æ ‡æ³¨è¯åçš„ä¹¦å
    - ç¬¬äºŒä¼˜å…ˆçº§ï¼šæŒ‰è¯é•¿åº¦é™åºæ’åˆ—çš„å…³é”®è¯ï¼ˆæœ€å¤š5ä¸ªï¼‰
    
    Args:
        cleaned_title: å·²æ¸…æ´—çš„ä¹¦åï¼ˆé€šå¸¸æ¥è‡ª normalize_queryï¼‰
        
    Returns:
        ä¹¦åå˜ä½“åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åºã€‚å¦‚æœè¾“å…¥ä¸ºç©ºåˆ™è¿”å›ç©ºåˆ—è¡¨
    """
    if not cleaned_title:
        return []

    variations = []
    
    # ç­–ç•¥1ï¼šå»é™¤å¸¸è§æ ‡æ³¨è¯åç”Ÿæˆå˜ä½“
    # è¿™äº›æ ‡æ³¨è¯é€šå¸¸ä¸å½±å“ä¹¦ç±çš„æ ¸å¿ƒä¿¡æ¯ï¼Œä½†å¯èƒ½å¹²æ‰°æœç´¢åŒ¹é…
    stopwords = ['å®Œç»“', 'å®Œæœ¬', 'è¿è½½', 'ç•ªå¤–', 'å…¨æœ¬', 'txt', 'å…¨æ–‡', 'ç•ªå¤–ç¯‡']
    short = cleaned_title
    for w in stopwords:
        short = short.replace(w, ' ')  # å°†æ ‡æ³¨è¯æ›¿æ¢ä¸ºç©ºæ ¼
    short = re.sub(r"\s+", ' ', short).strip()  # å‹ç¼©ç©ºæ ¼
    # å¦‚æœå»é™¤æ ‡æ³¨è¯åä»æœ‰å†…å®¹ä¸”ä¸åŸä¹¦åä¸åŒï¼Œåˆ™åŠ å…¥å˜ä½“åˆ—è¡¨
    if short and short != cleaned_title:
        variations.append(short)

    # ç­–ç•¥2ï¼šæŒ‰è¯é•¿åº¦é™åºæå–å…³é”®è¯
    # å°†ä¹¦åæŒ‰ç©ºæ ¼åˆ†è¯ï¼ŒæŒ‰é•¿åº¦ä»é•¿åˆ°çŸ­æ’åºï¼Œä¼˜å…ˆä½¿ç”¨è¾ƒé•¿çš„è¯ï¼ˆé€šå¸¸æ›´å…·ä½“ï¼‰
    tokens = [t for t in re.split(r"\s+", cleaned_title) if t]
    tokens = sorted(tokens, key=lambda x: len(x), reverse=True)
    # æœ€å¤šå–å‰5ä¸ªå…³é”®è¯ï¼Œä¸”é•¿åº¦è‡³å°‘ä¸º2ä¸ªå­—ç¬¦ï¼ˆé¿å…å•å­—ç¬¦å¹²æ‰°ï¼‰
    for t in tokens[:5]:
        if len(t) >= 2 and t not in variations:
            variations.append(t)

    return variations

# ============================================================================
# æ™‹æ±Ÿæ–‡å­¦åŸæ ¸å¿ƒé…ç½®
# ============================================================================

# åŸºç¡€ URL é…ç½®
JINJIANG_BASE_URL = "https://www.jjwxc.net/"  # æ™‹æ±Ÿæ–‡å­¦åŸä¸»ç«™
JINJIANG_M_BASE_URL = "https://m.jjwxc.net/"  # ç§»åŠ¨ç«¯ç½‘ç«™
JINJIANG_APP_BASE_URL = "https://app.jjwxc.org/"  # APP æ¥å£åŸŸå

# æœç´¢æ¥å£ URL
JINJIANG_SEARCH_WEB_URL = "https://www.jjwxc.net/search.php"  # ç½‘é¡µæœç´¢æ¥å£ï¼ˆå·²å¼ƒç”¨ï¼Œä»…ä½œå¤‡é€‰ï¼‰
JINJIANG_SEARCH_APP_URL = "https://app.jjwxc.org/search/searchV3"  # APP æœç´¢æ¥å£ V3ï¼ˆæ¨èï¼Œæ›´ç¨³å®šï¼‰
JINJIANG_SEARCH_APP_ANDROID_API = "https://app.jjwxc.org/androidapi/search"  # Android API æœç´¢æ¥å£ï¼ˆå¤‡é€‰ï¼‰

# ä¹¦ç±è¯¦æƒ…æ¥å£ URL
JINJIANG_BOOK_DETAIL_WEB_URL = "https://www.jjwxc.net/onebook.php?novelid=%s"  # ç½‘é¡µè¯¦æƒ…é¡µï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
JINJIANG_BOOK_DETAIL_APP_URL = "https://app.jjwxc.org/androidapi/getBookDetail"  # APP è¯¦æƒ…æ¥å£ï¼ˆæ¨èï¼‰

# æ­£åˆ™è¡¨è¾¾å¼ï¼šä» URL ä¸­æå–ä¹¦ç± ID
JINJIANG_BOOK_ID_PATTERN = re.compile(r"novelid=(\d+)")

# æ’ä»¶å…ƒä¿¡æ¯
PROVIDER_NAME = "Jinjiang Books"  # æ’ä»¶æ˜¾ç¤ºåç§°
PROVIDER_ID = "jinjiang_enhanced"  # æ’ä»¶å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆç”¨äº Calibre çš„ identifierï¼‰
PROVIDER_VERSION = (0, 3, 0) # æ’ä»¶ç‰ˆæœ¬å·
PROVIDER_AUTHOR = 'Qishan '  # æ’ä»¶ä½œè€…

# å¹¶å‘é…ç½®
JINJIANG_CONCURRENCY_SIZE = 5  # é»˜è®¤å¹¶å‘è¯·æ±‚æ•°ï¼ˆå»ºè®®ä¸è¶…è¿‡5ï¼Œé¿å…è§¦å‘åçˆ¬è™«æœºåˆ¶ï¼‰

# æœç´¢ç±»å‹æ˜ å°„ï¼ˆå¯¹åº”æ™‹æ±Ÿ APP API ä¸­çš„æœç´¢ç±»å‹å‚æ•°ï¼‰
# è¿™äº›ç±»å‹å€¼ç”¨äºæŒ‡å®šæœç´¢èŒƒå›´ï¼šä¹¦åã€ä½œè€…ã€è§’è‰²ã€ID ç­‰
SEARCH_TYPE_MAP = {
    "book": 1,        # æŒ‰ä¹¦åæœç´¢ï¼ˆé»˜è®¤ç±»å‹ï¼‰
    "author": 2,      # æŒ‰ä½œè€…æœç´¢ï¼ˆJSON æ ¼å¼ï¼š#å…³é”®è¯#ï¼‰
    "protagonist": 4, # æŒ‰ä¸»è§’æœç´¢ï¼ˆJSON æ ¼å¼ï¼šä¸»è§’#å…³é”®è¯#ï¼‰
    "supporting": 5,  # æŒ‰é…è§’æœç´¢ï¼ˆJSON æ ¼å¼ï¼šé…è§’#å…³é”®è¯#ï¼‰
    "other": 6,       # æŒ‰å…¶ä»–å…³é”®å­—æœç´¢ï¼ˆJSON æ ¼å¼ï¼šå…¶ä»–#å…³é”®è¯#ï¼‰
    "id": 7           # æŒ‰ä½œå“ ID æœç´¢ï¼ˆJSON æ ¼å¼ï¼šID#å…³é”®è¯#ï¼‰
}


class JinjiangBookSearcher:
    """
    æ™‹æ±Ÿä¹¦ç±æœç´¢å™¨
    
    è´Ÿè´£ä»æ™‹æ±Ÿæ–‡å­¦åŸæœç´¢å’Œè·å–ä¹¦ç±ä¿¡æ¯ï¼Œæ”¯æŒï¼š
    - å¤šç§æœç´¢ç±»å‹ï¼ˆä¹¦åã€ä½œè€…ã€è§’è‰²ã€IDç­‰ï¼‰
    - APP API å’Œç½‘é¡µæ¥å£çš„è‡ªåŠ¨åˆ‡æ¢
    - å¹¶å‘è¯·æ±‚å¤„ç†
    - ç™»å½• Cookie æ”¯æŒ
    """
    
    def __init__(self, *args, **kwargs):
        """
        åˆå§‹åŒ–æœç´¢å™¨
        
        å…¼å®¹æ€§æ„é€ å‡½æ•°ï¼šæ¥å—å¤šç§å‚æ•°å½¢å¼ï¼Œé¿å…å› å‚æ•°åä¸åŒå¯¼è‡´çš„é”™è¯¯ã€‚
        æ”¯æŒä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨å…³é”®å­—å‚æ•°ã€‚
        
        å‚æ•°è¯´æ˜ï¼š
        - concurrency_size / max_workers: å¹¶å‘è¯·æ±‚æ•°ï¼ˆé»˜è®¤5ï¼‰
        - jinjiang_delay_enable: æ˜¯å¦å¯ç”¨éšæœºå»¶è¿Ÿï¼ˆé»˜è®¤Trueï¼Œç”¨äºé¿å…åçˆ¬è™«ï¼‰
        - jinjiang_login_cookie: ç™»å½•åçš„ Cookie å­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼Œç”¨äºè®¿é—® VIP å†…å®¹ï¼‰
        - jinjiang_search_with_author: æ˜¯å¦åœ¨æœç´¢æ—¶åŒ…å«ä½œè€…åï¼ˆé»˜è®¤Falseï¼‰
        - jinjiang_prefer_app_api: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨ APP APIï¼ˆé»˜è®¤Trueï¼‰
        
        Args:
            *args: ä½ç½®å‚æ•°ï¼ŒæŒ‰é¡ºåºä¸ºï¼šmax_workers, delay_enable, login_cookie
            **kwargs: å…³é”®å­—å‚æ•°ï¼Œæ”¯æŒä¸Šè¿°æ‰€æœ‰å‚æ•°å
        """
        # è§£æä½ç½®å‚æ•°ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬è°ƒç”¨æ–¹å¼ï¼‰
        # ä½ç½®å‚æ•°é¡ºåºï¼šmax_workers, jinjiang_delay_enable, jinjiang_login_cookie
        pos_max_workers = args[0] if len(args) > 0 else None
        pos_delay = args[1] if len(args) > 1 else None
        pos_cookie = args[2] if len(args) > 2 else None

        # å¹¶å‘å‚æ•°å¤„ç†ï¼šä¼˜å…ˆçº§ä¸º kwargs > ä½ç½®å‚æ•° > é»˜è®¤å€¼
        # æ”¯æŒ concurrency_size å’Œ max_workers ä¸¤ç§å‚æ•°å
        concurrency = kwargs.pop('concurrency_size', None)
        if concurrency is None:
            concurrency = kwargs.pop('max_workers', None)
        if concurrency is None:
            concurrency = pos_max_workers
        try:
            self.max_workers = int(concurrency) if concurrency is not None else JINJIANG_CONCURRENCY_SIZE
        except Exception:
            self.max_workers = JINJIANG_CONCURRENCY_SIZE

        # å…¶ä»–é…ç½®é€‰é¡¹ï¼ˆå¸¦é»˜è®¤å€¼ï¼‰
        # å¦‚æœæä¾›äº†ä½ç½®å‚æ•°åˆ™ä¼˜å…ˆä½¿ç”¨ä½ç½®å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨ kwargs æˆ–é»˜è®¤å€¼
        self.jinjiang_delay_enable = kwargs.pop('jinjiang_delay_enable', pos_delay if pos_delay is not None else True)
        self.jinjiang_login_cookie = kwargs.pop('jinjiang_login_cookie', pos_cookie if pos_cookie is not None else None)
        self.jinjiang_search_with_author = kwargs.pop('jinjiang_search_with_author', False)
        self.jinjiang_prefer_app_api = kwargs.pop('jinjiang_prefer_app_api', True)

        # åˆå§‹åŒ– HTML è§£æå™¨ï¼ˆç”¨äºç½‘é¡µæ¥å£çš„å›é€€æ–¹æ¡ˆï¼‰
        self.book_parser = JinjiangBookHtmlParser()
        
        # åˆå§‹åŒ–çº¿ç¨‹æ± ï¼Œé™åˆ¶æœ€å¤§çº¿ç¨‹æ•°åœ¨ 1-20 ä¹‹é—´ï¼Œé¿å…è¯¯è®¾ç½®è¿‡å¤§å¯¼è‡´èµ„æºæµªè´¹
        max_workers_safe = max(1, min(self.max_workers, 20))
        self.thread_pool = ThreadPoolExecutor(max_workers=max_workers_safe, thread_name_prefix='jinjiang_async')

        # ä» Cookie ä¸­æå– sidï¼ˆä¼šè¯IDï¼Œç”¨äº APP æ¥å£çš„èº«ä»½éªŒè¯ï¼‰
        self.sid = self.extract_sid_from_cookie()

    def extract_sid_from_cookie(self):
        """
        ä»ç™»å½• Cookie ä¸­æå– sidï¼ˆä¼šè¯IDï¼‰
        
        sid æ˜¯æ™‹æ±Ÿ APP æ¥å£è¿›è¡Œèº«ä»½éªŒè¯æ‰€éœ€çš„å‚æ•°ã€‚æœ¬æ–¹æ³•å°è¯•ä» Cookie å­—ç¬¦ä¸²ä¸­
        æå– sidï¼Œæ”¯æŒå¤šç§ Cookie æ ¼å¼å’Œå­—æ®µåã€‚
        
        æå–ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
        1. ç›´æ¥æŸ¥æ‰¾ sid= å­—æ®µ
        2. æŸ¥æ‰¾ token= æˆ– bbstoken= å­—æ®µï¼ˆURL è§£ç åä½¿ç”¨ï¼‰
        3. ä» JJSESS Cookie çš„ JSON æ•°æ®ä¸­æå–ï¼ˆæ”¯æŒ sid/sidkey/token å­—æ®µï¼‰
        4. å…¶ä»–å¸¸è§å­—æ®µï¼ˆå¦‚ JJEVERï¼Œä½†é€šå¸¸ä¸åŒ…å« sidï¼‰
        
        Returns:
            æå–åˆ°çš„ sid å­—ç¬¦ä¸²ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
        """
        if not self.jinjiang_login_cookie:
            return None

        c = self.jinjiang_login_cookie
        
        # ç­–ç•¥1ï¼šç›´æ¥æŸ¥æ‰¾ sid= å­—æ®µï¼ˆæœ€å¸¸è§çš„æƒ…å†µï¼‰
        m = re.search(r"sid=([^;\s]+)", c)
        if m:
            return m.group(1)

        # ç­–ç•¥2ï¼šæŸ¥æ‰¾ token= æˆ– bbstoken= å­—æ®µ
        # è¿™äº›å­—æ®µçš„å€¼å¯èƒ½ç»è¿‡ URL ç¼–ç ï¼Œéœ€è¦è§£ç 
        m = re.search(r"token=([^;\s]+)", c)
        if m:
            return unquote(m.group(1))
        m = re.search(r"bbstoken=([^;\s]+)", c)
        if m:
            return unquote(m.group(1))

        # ç­–ç•¥3ï¼šä» JJSESS Cookie ä¸­æå–
        # JJSESS å¯èƒ½åŒ…å« JSON æ ¼å¼çš„æ•°æ®ï¼Œå…¶ä¸­åŒ…å« sid/sidkey/token ç­‰å­—æ®µ
        m = re.search(r"JJSESS=([^;]+)", c)
        if m:
            raw = unquote(m.group(1))
            try:
                # å°è¯•å°† JJSESS çš„å€¼è§£æä¸º JSON å¯¹è±¡
                j = json.loads(raw)
                if isinstance(j, dict):
                    # åœ¨ JSON å¯¹è±¡ä¸­æŸ¥æ‰¾ sidã€sidkey æˆ– token å­—æ®µ
                    for key in ('sid', 'sidkey', 'token'):
                        if key in j and j[key]:
                            return j[key]
            except Exception:
                # å¦‚æœè§£æ JSON å¤±è´¥ï¼Œå°è¯•ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»å­—ç¬¦ä¸²ä¸­æå– sidkey
                m2 = re.search(r"sidkey\W*[:=]\W*'?\"?([\w-]+)'?\"?", raw)
                if m2:
                    return m2.group(1)

        # ç­–ç•¥4ï¼šå°è¯•å…¶ä»–å¸¸è§å­—æ®µï¼ˆå¦‚ JJEVERï¼‰
        # æ³¨æ„ï¼šJJEVER é€šå¸¸åŒ…å«ç”¨æˆ·ä¿¡æ¯ï¼Œä½†ä¸ç›´æ¥åŒ…å« sidï¼Œå› æ­¤ä¸åšè¿›ä¸€æ­¥è§£æ
        m = re.search(r"JJEVER=([^;\s]+)", c)
        if m:
            # JJEVER æœ‰æ—¶åŒ…å«ç”¨æˆ·ä¿¡æ¯ï¼Œä½†ä¸æ˜¯ç›´æ¥ sidï¼›ä¸åšè¿›ä¸€æ­¥è§£æ
            return None

        return None

    def parse_search_keyword(self, query):
        """
        è§£ææœç´¢å…³é”®è¯ï¼Œè¯†åˆ«æœç´¢ç±»å‹
        
        æ”¯æŒå¤šç§æœç´¢å…³é”®è¯æ ¼å¼ï¼Œç”¨äºæŒ‡å®šä¸åŒçš„æœç´¢ç±»å‹ï¼ˆä¹¦åã€ä½œè€…ã€è§’è‰²ã€IDç­‰ï¼‰ã€‚
        è§£æåçš„æœç´¢ç±»å‹å°†ä¼ é€’ç»™æ™‹æ±Ÿ API è¿›è¡Œç›¸åº”ç±»å‹çš„æœç´¢ã€‚
        
        æ”¯æŒçš„æ ¼å¼ï¼š
        1. URL å‚æ•°æ ¼å¼ï¼št=2 å…³é”®è¯ æˆ– type=2 å…³é”®è¯ï¼ˆæ•°å­—å¯¹åº” SEARCH_TYPE_MAPï¼‰
        2. ä¸­æ–‡å‰ç¼€æ ¼å¼ï¼šä½œè€…:xxxã€ä¸»è§’:xxxã€é…è§’:xxxã€å…¶å®ƒ:xxxã€ID:xxx
        3. è‹±æ–‡å‰ç¼€æ ¼å¼ï¼šauthor:xxxã€protagonist:xxxã€supporting:xxxã€other:xxxã€id:xxx
        4. JSON è§„åˆ™æ ¼å¼ï¼š#å…³é”®è¯#ï¼ˆä½œè€…ï¼‰ã€ä¸»è§’#å…³é”®è¯#ã€é…è§’#å…³é”®è¯#ã€å…¶ä»–#å…³é”®è¯#ã€ID#å…³é”®è¯#
        5. é»˜è®¤ï¼šæ— å‰ç¼€æ—¶æŒ‰ä¹¦åæœç´¢
        
        Args:
            query: åŸå§‹æœç´¢å…³é”®è¯å­—ç¬¦ä¸²
            
        Returns:
            tuple: (æ¸…æ´—åçš„å…³é”®è¯, æœç´¢ç±»å‹ä»£ç )
                  æœç´¢ç±»å‹ä»£ç å¯¹åº” SEARCH_TYPE_MAP ä¸­çš„å€¼ï¼Œé»˜è®¤ä¸º 1ï¼ˆä¹¦åæœç´¢ï¼‰
        """
        search_type = SEARCH_TYPE_MAP["book"]  # é»˜è®¤æœç´¢ä¹¦å

        if not query:
            return query, search_type

        q = query.strip()

        # æ ¼å¼1ï¼šURL å‚æ•°æ ¼å¼ï¼ˆt=2 æˆ– type=2ï¼‰
        # ç¤ºä¾‹: "t=2 æˆ‘å–œæ¬¢ä½ çš„ä¿¡æ¯ç´ " æˆ– "type=2 ä½œè€…å"
        m = re.match(r'^(?:t|type)\s*[:=]\s*(\d+)\s*(.*)$', q, re.I)
        if m:
            try:
                tnum = int(m.group(1))
                rest = m.group(2).strip()
                # éªŒè¯ç±»å‹ä»£ç æ˜¯å¦æœ‰æ•ˆ
                if tnum in SEARCH_TYPE_MAP.values():
                    return (rest or query, tnum)
            except Exception:
                pass

        # æ ¼å¼2ï¼šä¸­æ–‡/è‹±æ–‡å‰ç¼€æ ¼å¼ï¼ˆæ”¯æŒä¸­è‹±æ–‡å†’å·ï¼‰
        # ä½œè€…æœç´¢ï¼šä½œè€…:xxx æˆ– author:xxx
        m = re.match(r'^(?:ä½œè€…|author)\s*[:ï¼š]\s*(.+)$', q, re.I)
        if m:
            return m.group(1).strip(), SEARCH_TYPE_MAP['author']

        # ä¸»è§’æœç´¢ï¼šä¸»è§’:xxx æˆ– protagonist:xxx
        m = re.match(r'^(?:ä¸»è§’|protagonist)\s*[:ï¼š]\s*(.+)$', q, re.I)
        if m:
            return m.group(1).strip(), SEARCH_TYPE_MAP['protagonist']

        # é…è§’æœç´¢ï¼šé…è§’:xxx æˆ– supporting:xxx
        m = re.match(r'^(?:é…è§’|supporting)\s*[:ï¼š]\s*(.+)$', q, re.I)
        if m:
            return m.group(1).strip(), SEARCH_TYPE_MAP['supporting']

        # å…¶ä»–å…³é”®å­—æœç´¢ï¼šå…¶å®ƒ:xxxã€å…¶ä»–:xxx æˆ– other:xxx
        m = re.match(r'^(?:å…¶å®ƒ|å…¶ä»–|other)\s*[:ï¼š]\s*(.+)$', q, re.I)
        if m:
            return m.group(1).strip(), SEARCH_TYPE_MAP['other']

        # ID æœç´¢ï¼šID:xxxã€æ–‡ç« ID:xxx æˆ– id:xxx
        m = re.match(r'^(?:ID|æ–‡ç« ID|id)\s*[:ï¼š]\s*(.+)$', q, re.I)
        if m:
            return m.group(1).strip(), SEARCH_TYPE_MAP['id']

        # æ ¼å¼3ï¼šJSON è§„åˆ™æ ¼å¼ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        # #å…³é”®è¯# è¡¨ç¤ºæŒ‰ä½œè€…æœç´¢
        if q.startswith("#") and q.endswith("#"):
            inner = q.strip("#").strip()
            return inner, SEARCH_TYPE_MAP['author']
        # ä¸»è§’#å…³é”®è¯# è¡¨ç¤ºæŒ‰ä¸»è§’æœç´¢
        elif q.startswith("ä¸»è§’#") and q.endswith("#"):
            inner = q[len("ä¸»è§’#"):-1].strip()
            return inner, SEARCH_TYPE_MAP['protagonist']
        # é…è§’#å…³é”®è¯# è¡¨ç¤ºæŒ‰é…è§’æœç´¢
        elif q.startswith("é…è§’#") and q.endswith("#"):
            inner = q[len("é…è§’#"):-1].strip()
            return inner, SEARCH_TYPE_MAP['supporting']
        # å…¶ä»–#å…³é”®è¯# è¡¨ç¤ºæŒ‰å…¶ä»–å…³é”®å­—æœç´¢
        elif q.startswith("å…¶ä»–#") and q.endswith("#"):
            inner = q[len("å…¶ä»–#"):-1].strip()
            return inner, SEARCH_TYPE_MAP['other']
        # ID#å…³é”®è¯# è¡¨ç¤ºæŒ‰ä½œå“ ID æœç´¢
        elif q.startswith("ID#") and q.endswith("#"):
            inner = q[len("ID#"):-1].strip()
            return inner, SEARCH_TYPE_MAP['id']

        # é»˜è®¤ï¼šæ— å‰ç¼€æ—¶æŒ‰ä¹¦åæœç´¢
        return query, search_type

    def search_via_app_api(self, query, search_type, log):
        """
        é€šè¿‡ APP æœç´¢æ¥å£è·å–ä¹¦ç±åˆ—è¡¨
        
        APP æ¥å£ç›¸æ¯”ç½‘é¡µæ¥å£æ›´ç¨³å®šï¼Œåçˆ¬è™«æœºåˆ¶è¾ƒå¼±ï¼Œè¿”å›çš„æ•°æ®æ ¼å¼ä¹Ÿæ›´è§„èŒƒã€‚
        æœ¬æ–¹æ³•ä¼šå°è¯•å¤šä¸ª APP æœç´¢æ¥å£ï¼ŒæŒ‰ä¼˜å…ˆçº§ä¾æ¬¡å°è¯•ï¼Œç›´åˆ°æˆåŠŸè·å–ç»“æœã€‚
        
        æœç´¢æµç¨‹ï¼š
        1. æ£€æŸ¥æ˜¯å¦æœ‰ sidï¼ˆä¼šè¯IDï¼‰ï¼Œæ—  sid åˆ™æ— æ³•ä½¿ç”¨ APP æ¥å£
        2. ä¼˜å…ˆå°è¯• searchV3 æ¥å£ï¼ˆæ›´ç¨³å®šï¼‰
        3. å¦‚æœ searchV3 å¤±è´¥ï¼Œå›é€€åˆ° androidapi/search æ¥å£
        4. è§£æè¿”å›çš„ JSON æ•°æ®ï¼Œæå–ä¹¦ç± ID å¹¶æ„å»ºè¯¦æƒ…é¡µ URL
        
        Args:
            query: æœç´¢å…³é”®è¯ï¼ˆå·²æ¸…æ´—ï¼‰
            search_type: æœç´¢ç±»å‹ä»£ç ï¼ˆå¯¹åº” SEARCH_TYPE_MAP ä¸­çš„å€¼ï¼‰
            log: æ—¥å¿—è®°å½•å™¨å¯¹è±¡
            
        Returns:
            ä¹¦ç±è¯¦æƒ…é¡µ URL åˆ—è¡¨ï¼Œå¦‚æœæœç´¢å¤±è´¥æˆ–æœªæ‰¾åˆ°ç»“æœåˆ™è¿”å›ç©ºåˆ—è¡¨
        """
        book_urls = []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ sidï¼ˆAPP æ¥å£å¿…éœ€çš„èº«ä»½éªŒè¯å‚æ•°ï¼‰
        if not self.sid:
            log.warning("APPæ¥å£éœ€è¦ç™»å½•Cookieï¼ˆå«sidï¼‰ï¼Œåˆ‡æ¢åˆ°ç½‘é¡µæœç´¢")
            return book_urls
        
        # é…ç½® SSL ä¸Šä¸‹æ–‡ï¼šç¦ç”¨ä¸»æœºåéªŒè¯å’Œè¯ä¹¦éªŒè¯
        # è¿™å¯ä»¥é¿å…æœ¬åœ°è¯ä¹¦é—®é¢˜ï¼Œä½†ä¼šé™ä½å®‰å…¨æ€§ï¼ˆä»…ç”¨äºå¼€å‘ç¯å¢ƒï¼‰
        ctx = ssl.create_default_context()
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE

        tried = []  # è®°å½•å°è¯•è¿‡çš„ URLï¼Œç”¨äºè°ƒè¯•

        # è¾…åŠ©å‡½æ•°ï¼šä» JSON å“åº”ä¸­æå–ä¹¦ç±åˆ—è¡¨
        # å…¼å®¹å¤šç§å¯èƒ½çš„ JSON ç»“æ„ï¼ˆä¸åŒæ¥å£å¯èƒ½è¿”å›ä¸åŒæ ¼å¼ï¼‰
        def _extract_books_from_json(data):
            books_list = []
            if not data:
                return books_list
            
            # å…¼å®¹å¤šç§ JSON å“åº”ç»“æ„
            if isinstance(data, dict):
                # ç»“æ„1ï¼š{ code:0, data: { books: [...] } }ï¼ˆæ ‡å‡†å“åº”æ ¼å¼ï¼‰
                if data.get('code') == 0 and data.get('data'):
                    d = data.get('data')
                    # data å¯¹è±¡ä¸­å¯èƒ½ä½¿ç”¨ä¸åŒçš„é”®åå­˜å‚¨ä¹¦ç±åˆ—è¡¨
                    books_list = d.get('books') or d.get('results') or d.get('items') or d.get('list') or []
                else:
                    # ç»“æ„2ï¼šç›´æ¥åœ¨é¡¶å±‚åŒ…å«ä¹¦ç±åˆ—è¡¨çš„é”®
                    books_list = data.get('books') or data.get('results') or data.get('items') or data.get('list') or []
            elif isinstance(data, list):
                # ç»“æ„3ï¼šç›´æ¥è¿”å›æ•°ç»„
                books_list = data
            return books_list

        # ç­–ç•¥1ï¼šä¼˜å…ˆå°è¯• searchV3 æ¥å£ï¼ˆæ›´ç¨³å®šå¯é ï¼‰
        try:
            params = {'keyword': query, 'type': search_type, 'page': 1}
            if self.sid:
                params['token'] = self.sid
            url = JINJIANG_SEARCH_APP_URL + '?' + urlencode(params)
            tried.append(url)
            log.info(f"Trying APP searchV3 URL: {url}")
            res = urlopen(Request(url, headers=self.get_headers(), method='GET'), timeout=15, context=ctx)
            if res.status in (200, 201):
                content = self.get_res_content(res)
                try:
                    data = json.loads(content)
                except Exception:
                    data = None
                books = _extract_books_from_json(data)
                if books:
                    for book in books:
                        novelid = book.get('novelid') or book.get('bookId') or book.get('id')
                        if novelid and len(book_urls) < self.max_workers:
                            detail_url = JINJIANG_BOOK_DETAIL_WEB_URL % novelid
                            book_urls.append(detail_url)
                            log.info(f"searchV3 found book: {book.get('bookname') or book.get('title')} (ID: {novelid})")
                    return book_urls
                else:
                    log.debug('searchV3 returned no books')
        except Exception as e:
            log.debug(f"searchV3 request failed: {e}")

        # ç­–ç•¥2ï¼šå¦‚æœ searchV3 å¤±è´¥ï¼Œå›é€€åˆ° androidapi/search æ¥å£
        try:
            params = {'versionCode': 282, 'keyword': query, 'type': search_type, 'page': 1}
            if self.sid:
                params['token'] = self.sid
            url2 = JINJIANG_SEARCH_APP_ANDROID_API + '?' + urlencode(params)
            tried.append(url2)
            log.info(f"APP androidapi search URL: {url2}")
            res2 = urlopen(Request(url2, headers=self.get_headers(), method='GET'), timeout=15, context=ctx)
            if res2.status in (200, 201):
                content2 = self.get_res_content(res2)
                try:
                    data2 = json.loads(content2)
                except Exception:
                    data2 = None
                books2 = _extract_books_from_json(data2)
                if books2:
                    for book in books2:
                        novelid = book.get('novelid') or book.get('bookId') or book.get('id')
                        if novelid and len(book_urls) < self.max_workers:
                            detail_url = JINJIANG_BOOK_DETAIL_WEB_URL % novelid
                            book_urls.append(detail_url)
                            log.info(f"androidapi found book: {book.get('bookname') or book.get('title')} (ID: {novelid})")
                    return book_urls
                else:
                    log.debug('androidapi returned no books')
                    # æŠŠå“åº”å†…å®¹å†™å…¥æ—¥å¿—ï¼ˆå‰2000å­—ç¬¦ï¼‰ï¼Œä¾¿äºè¯Šæ–­
                    try:
                        snippet = (content2 or '')[:2000]
                        log.debug(f"androidapi response snippet: {snippet}")
                    except Exception:
                        pass
        except Exception as e:
            log.debug(f"androidapi request failed: {e}")

        # è‹¥éƒ½æœªå‘½ä¸­ï¼Œè®°å½•å°è¯•è¿‡çš„ URL ä»¥ä¾¿æ’æŸ¥
        if tried:
            log.debug(f"Tried APP search URLs: {', '.join(tried)}")

        return book_urls

    def search_via_web(self, query, search_type, log):
        """
        ç½‘é¡µæœç´¢æ¥å£ï¼ˆå·²å¼ƒç”¨ï¼‰
        
        æ³¨æ„ï¼šç½‘é¡µæœç´¢åŠŸèƒ½å·²ç§»é™¤ï¼Œæ’ä»¶ç°åœ¨ä»…ä½¿ç”¨ APP æ¥å£è¿›è¡Œæœç´¢ã€‚
        ä¿ç•™æ­¤æ–¹æ³•æ˜¯ä¸ºäº†ä¿æŒæ¥å£å…¼å®¹æ€§ï¼Œå®é™…è°ƒç”¨æ—¶ç›´æ¥è¿”å›ç©ºåˆ—è¡¨ã€‚
        
        Args:
            query: æœç´¢å…³é”®è¯
            search_type: æœç´¢ç±»å‹ä»£ç 
            log: æ—¥å¿—è®°å½•å™¨å¯¹è±¡
            
        Returns:
            ç©ºåˆ—è¡¨ï¼ˆç½‘é¡µæœç´¢å·²ç¦ç”¨ï¼‰
        """
        log.debug('search_via_web called but web search has been removed; returning empty list')
        return []

    def load_book_urls_new(self, query, log):
        """
        ç»Ÿä¸€çš„æœç´¢å…¥å£æ–¹æ³•
        
        è§£ææœç´¢å…³é”®è¯ï¼Œè¯†åˆ«æœç´¢ç±»å‹ï¼Œç„¶åè°ƒç”¨ç›¸åº”çš„æœç´¢æ¥å£è·å–ä¹¦ç±åˆ—è¡¨ã€‚
        ç›®å‰ä»…ä½¿ç”¨ APP æ¥å£è¿›è¡Œæœç´¢ï¼ˆç½‘é¡µæœç´¢å·²å¼ƒç”¨ï¼‰ã€‚
        
        Args:
            query: åŸå§‹æœç´¢å…³é”®è¯ï¼ˆå¯èƒ½åŒ…å«ç±»å‹å‰ç¼€ï¼‰
            log: æ—¥å¿—è®°å½•å™¨å¯¹è±¡
            
        Returns:
            ä¹¦ç±è¯¦æƒ…é¡µ URL åˆ—è¡¨ï¼Œå¦‚æœæœç´¢å¤±è´¥åˆ™è¿”å›ç©ºåˆ—è¡¨
        """
        # æ­¥éª¤1ï¼šè§£ææœç´¢å…³é”®è¯ï¼Œè¯†åˆ«æœç´¢ç±»å‹
        query, search_type = self.parse_search_keyword(query)
        # è·å–æœç´¢ç±»å‹çš„åç§°ï¼ˆç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼‰
        type_name = [k for k, v in SEARCH_TYPE_MAP.items() if v == search_type][0] if search_type in SEARCH_TYPE_MAP.values() else 'unknown'
        log.info(f"Search query: {query}, type: {search_type} ({type_name})")
        
        # æ­¥éª¤2ï¼šè°ƒç”¨ APP æ¥å£è¿›è¡Œæœç´¢ï¼ˆç½‘é¡µæœç´¢å·²å¼ƒç”¨ï¼‰
        book_urls = self.search_via_app_api(query, search_type, log)
        if not book_urls:
            log.info('APPæ¥å£æœªè¿”å›ç»“æœ')
        return book_urls

    def search_books(self, query, authors, log):
        """
        æœç´¢ä¹¦ç±å¹¶è·å–è¯¦ç»†ä¿¡æ¯
        
        æ‰§è¡Œæœç´¢æ“ä½œï¼Œè·å–åŒ¹é…çš„ä¹¦ç±åˆ—è¡¨ï¼Œç„¶åå¹¶å‘åŠ è½½æ¯æœ¬ä¹¦çš„è¯¦ç»†ä¿¡æ¯ã€‚
        æ”¯æŒåœ¨æœç´¢æ—¶è‡ªåŠ¨æ·»åŠ ä½œè€…åä»¥æé«˜æœç´¢å‡†ç¡®æ€§ã€‚
        
        Args:
            query: æœç´¢å…³é”®è¯
            authors: ä½œè€…åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¦‚æœå¯ç”¨ jinjiang_search_with_author åˆ™ä¼šæ·»åŠ åˆ°æœç´¢å…³é”®è¯ä¸­ï¼‰
            log: æ—¥å¿—è®°å½•å™¨å¯¹è±¡
            
        Returns:
            ä¹¦ç±ä¿¡æ¯å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ä¸€æœ¬ä¹¦çš„å®Œæ•´å…ƒæ•°æ®
        """
        # å¦‚æœå¯ç”¨äº†"æœç´¢æ—¶åŒ…å«ä½œè€…"é€‰é¡¹ï¼Œå°†ä½œè€…åæ·»åŠ åˆ°æœç´¢å…³é”®è¯ä¸­
        if self.jinjiang_search_with_author and authors:
            author_str = ' '.join(authors)
            query = f'{query} {author_str}'
            log.info(f"Enhanced search query: {query}")
        
        # æ­¥éª¤1ï¼šè·å–åŒ¹é…çš„ä¹¦ç± URL åˆ—è¡¨
        book_urls = self.load_book_urls_new(query, log)
        books = []
        
        # æ­¥éª¤2ï¼šå¹¶å‘åŠ è½½æ¯æœ¬ä¹¦çš„è¯¦ç»†ä¿¡æ¯
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è¯·æ±‚ï¼Œæé«˜åŠ è½½æ•ˆç‡
        futures = [self.thread_pool.submit(self.load_book, url, log) for url in book_urls]
        
        # æ­¥éª¤3ï¼šæ”¶é›†æ‰€æœ‰å¹¶å‘ä»»åŠ¡çš„ç»“æœ
        for future in as_completed(futures):
            try:
                book = future.result()
                if book:
                    books.append(book)
            except Exception as e:
                log.error(f"Future error: {e}")
        
        return books

    # æ¦œå•/å‘ç°ç±»åŠŸèƒ½å·²å®Œå…¨ç§»é™¤ä»¥ç®€åŒ–æ’ä»¶è¡Œä¸ºï¼ˆä»…ä¿ç•™æŒ‰ä¹¦å/ä½œè€…çš„è¯†åˆ«ä¸å°é¢ä¸‹è½½ï¼‰

    def extract_novelid(self, href):
        """
        ä» URL ä¸­æå–ä¹¦ç± IDï¼ˆnovelidï¼‰
        
        æ”¯æŒå¤šç§ URL æ ¼å¼ï¼š
        - ç½‘é¡µæ ¼å¼ï¼šhttps://www.jjwxc.net/onebook.php?novelid=123456
        - APP æ ¼å¼ï¼šå¯èƒ½ä½¿ç”¨ bookId å‚æ•°
        
        Args:
            href: ä¹¦ç±è¯¦æƒ…é¡µ URL
            
        Returns:
            ä¹¦ç± ID å­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å› None
        """
        if not href:
            return None
        
        # è§£æ URL æŸ¥è¯¢å‚æ•°
        params = parse_qs(urlparse(href).query)
        
        # ä¼˜å…ˆæŸ¥æ‰¾ novelid å‚æ•°ï¼ˆç½‘é¡µæ ¼å¼ï¼‰
        novelids = params.get('novelid', [])
        if novelids:
            return novelids[0]
        
        # å¤‡é€‰ï¼šæŸ¥æ‰¾ bookId å‚æ•°ï¼ˆAPP æ¥å£æ ¼å¼ï¼‰
        book_ids = params.get('bookId', [])
        return book_ids[0] if book_ids else None

    def build_book_detail_url(self, novelid):
        """
        æ„å»ºä¹¦ç±è¯¦æƒ…é¡µ URL
        
        Args:
            novelid: ä¹¦ç± ID
            
        Returns:
            å®Œæ•´çš„ä¹¦ç±è¯¦æƒ…é¡µ URL å­—ç¬¦ä¸²
        """
        return JINJIANG_BOOK_DETAIL_WEB_URL % novelid

    def load_book(self, url, log):
        """
        åŠ è½½å¹¶è§£æä¹¦ç±è¯¦æƒ…ä¿¡æ¯
        
        åŠ è½½ç­–ç•¥ï¼š
        1. å¦‚æœå¯ç”¨äº†éšæœºå»¶è¿Ÿï¼Œå…ˆæ‰§è¡Œéšæœºå»¶è¿Ÿï¼ˆé¿å…åçˆ¬è™«ï¼‰
        2. ä¼˜å…ˆä½¿ç”¨ APP è¯¦æƒ…æ¥å£ï¼ˆå¦‚æœå·²é…ç½® sid ä¸”å¯ç”¨ prefer_app_apiï¼‰
        3. å¦‚æœ APP æ¥å£å¤±è´¥ï¼Œå›é€€åˆ°ç½‘é¡µè¯¦æƒ…é¡µè§£æ
        
        Args:
            url: ä¹¦ç±è¯¦æƒ…é¡µ URL
            log: æ—¥å¿—è®°å½•å™¨å¯¹è±¡
            
        Returns:
            ä¹¦ç±ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«æ ‡é¢˜ã€ä½œè€…ã€ç®€ä»‹ã€å°é¢ç­‰å­—æ®µã€‚å¦‚æœåŠ è½½å¤±è´¥åˆ™è¿”å› None
        """
        book = None
        start_time = time.time()
        
        # æ­¥éª¤1ï¼šå¦‚æœå¯ç”¨äº†å»¶è¿Ÿï¼Œå…ˆæ‰§è¡Œéšæœºå»¶è¿Ÿï¼ˆé¿å…è§¦å‘åçˆ¬è™«æœºåˆ¶ï¼‰
        if self.jinjiang_delay_enable:
            self.random_sleep(log)
        
        # æ­¥éª¤2ï¼šä» URL ä¸­æå–ä¹¦ç± ID
        novelid = self.extract_novelid(url)
        if not novelid:
            log.error(f"Cannot extract novelid from URL: {url}")
            return None
        
        # æ­¥éª¤3ï¼šä¼˜å…ˆä½¿ç”¨ APP è¯¦æƒ…æ¥å£ï¼ˆæ•°æ®æ›´ç»“æ„åŒ–ï¼Œè§£ææ›´å¯é ï¼‰
        if self.jinjiang_prefer_app_api and self.sid:
            book = self.load_book_via_app_api(novelid, log)
            if book:
                elapsed = (time.time() - start_time) * 1000
                log.info(f"APP API loaded book: {book['title']} (time: {elapsed:.0f}ms)")
                return book
            log.info(f"APP detail API failed, fallback to web page: {url}")
        
        # æ­¥éª¤4ï¼šå¦‚æœ APP æ¥å£å¤±è´¥ï¼Œå›é€€åˆ°ç½‘é¡µè¯¦æƒ…é¡µè§£æï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
        try:
            res = urlopen(Request(url, headers=self.get_headers(), method='GET'), timeout=10)
            if res.status in [200, 201]:
                elapsed = (time.time() - start_time) * 1000
                log.info(f"Web loaded book: {url} (time: {elapsed:.0f}ms)")
                book_detail_content = self.get_res_content(res)
                book = self.book_parser.parse_book(url, book_detail_content, log)
        except Exception as e:
            log.error(f"Web load book failed: {e}")
        
        return book

    def fetch_and_merge_other_info(self, novelid, book, log=None, base_data=None):
        """
        ä» APP çš„ getnovelOtherInfo æ¥å£è·å–æ‰©å±•ä¿¡æ¯å¹¶åˆå¹¶åˆ°ä¹¦ç±æè¿°ä¸­
        
        æœ¬æ–¹æ³•ä»æ™‹æ±Ÿ APP çš„æ‰©å±•ä¿¡æ¯æ¥å£è·å–ä¹¦ç±çš„è¯¦ç»†å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
        - æ–‡ç« ç±»å‹ã€å…¨æ–‡å­—æ•°ã€éVç‚¹å‡»ã€æ–‡ç« ç§¯åˆ†
        - ç­¾çº¦çŠ¶æ€ã€æ”¶è—æ•°ã€æ’åã€è¥å…»å€¼/è¯„åˆ†
        - æ‰©å±•ç®€ä»‹ã€æ ‡ç­¾ã€ä¸»è§’/é…è§’/å…¶ä»–è§’è‰²
        - é£æ ¼ã€è§†è§’ã€ç³»åˆ—ä¿¡æ¯ã€ä½œè€…ç•™è¨€ç­‰
        
        è¿™äº›ä¿¡æ¯ä¼šè¢«æ ¼å¼åŒ–ååˆå¹¶åˆ° book å­—å…¸çš„ description å’Œ description_html å­—æ®µä¸­ï¼Œ
        åŒæ—¶éƒ¨åˆ†ä¿¡æ¯ä¹Ÿä¼šæ›´æ–°åˆ° book çš„å…¶ä»–å­—æ®µï¼ˆå¦‚ tagsã€comments ç­‰ï¼‰ã€‚
        
        æ³¨æ„ï¼š
        - æ‰€æœ‰é”™è¯¯éƒ½ä¼šè¢«æ•è·ï¼Œä¸ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œä»¥å…å½±å“ä¸»æµç¨‹
        - å¼‚å¸¸ä¿¡æ¯ä¼šè®°å½•åˆ° log.debug ä¸­ï¼Œä¾¿äºè°ƒè¯•
        - å¦‚æœæ¥å£è¯·æ±‚å¤±è´¥æˆ–è§£æå¤±è´¥ï¼Œæ–¹æ³•ä¼šé™é»˜è¿”å›ï¼Œä¸å½±å“ä¹¦ç±åŸºæœ¬ä¿¡æ¯
        
        Args:
            novelid: ä¹¦ç± ID
            book: ä¹¦ç±ä¿¡æ¯å­—å…¸ï¼ˆä¼šè¢«ä¿®æ”¹ï¼Œæ·»åŠ æ‰©å±•ä¿¡æ¯ï¼‰
            log: æ—¥å¿—è®°å½•å™¨å¯¹è±¡ï¼ˆå¯é€‰ï¼‰
            base_data: åŸºç¡€æ•°æ®å­—å…¸ï¼ˆå¯é€‰ï¼Œç”¨äºè¡¥å……ä¿¡æ¯æºï¼‰
        """
        if not novelid:
            return

        try:
            # æ­¥éª¤1ï¼šæ„å»ºè¯·æ±‚ URL å¹¶å‘é€è¯·æ±‚
            params = {'versionCode': 279, 'novelId': novelid, 'type': 'novelbasicinfo'}
            url = 'https://app.jjwxc.org/androidapi/getnovelOtherInfo' + '?' + urlencode(params)
            
            # é…ç½® SSL ä¸Šä¸‹æ–‡ï¼ˆç¦ç”¨éªŒè¯ä»¥é¿å…è¯ä¹¦é—®é¢˜ï¼‰
            ctx = ssl.create_default_context()
            ctx.check_hostname = False
            ctx.verify_mode = ssl.CERT_NONE
            
            if log:
                log.debug(f'Trying other-info URL: {url}')
            res = urlopen(Request(url, headers=self.get_headers(), method='GET'), timeout=10, context=ctx)
            if res.status not in (200, 201):
                return
            
            # æ­¥éª¤2ï¼šè§£æå“åº”å†…å®¹
            content = self.get_res_content(res)
            try:
                data = json.loads(content)
            except Exception:
                data = None

            # æ­¥éª¤3ï¼šä»å“åº”ä¸­æå–æœ‰æ•ˆæ•°æ®å¯¹è±¡ï¼ˆå…¼å®¹å¤šç§ JSON å°è£…æ ¼å¼ï¼‰
            other = None
            if isinstance(data, dict):
                # å°è¯•ä»å¸¸è§åµŒå¥—é”®ä¸­æå–æ•°æ®
                for k in ('data', 'a', 'novelLeave', 'novel', 'result'):
                    if k in data and data[k]:
                        other = data[k]
                        break
                # å¦‚æœæœªæ‰¾åˆ°åµŒå¥—æ•°æ®ï¼Œä½¿ç”¨æ•´ä¸ªå­—å…¸
                if other is None:
                    other = data
            elif isinstance(data, list) and data:
                # å¦‚æœæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                other = data[0]
            else:
                other = data

            if not other:
                return

            # è¾…åŠ©å‡½æ•°ï¼šä»å¯¹è±¡ä¸­æå–å­—æ®µå€¼ï¼ˆæ”¯æŒå¤šç§é”®åå˜ä½“å’ŒåµŒå¥—æŸ¥æ‰¾ï¼‰
            # ç‰¹ç‚¹ï¼š
            # - å¤§å°å†™ä¸æ•æ„Ÿ
            # - ä¸‹åˆ’çº¿ä¸æ•æ„Ÿï¼ˆæ”¯æŒ camelCase å’Œ snake_caseï¼‰
            # - æ”¯æŒåµŒå¥—æŸ¥æ‰¾ï¼ˆåœ¨ data/novel/result ç­‰åµŒå¥—å¯¹è±¡ä¸­æŸ¥æ‰¾ï¼‰
            def pick(obj, *keys):
                if not obj:
                    return ''
                try:
                    if isinstance(obj, dict):
                        # åˆ›å»ºå°å†™é”®åæ˜ å°„ï¼ˆç”¨äºå¤§å°å†™ä¸æ•æ„ŸæŸ¥æ‰¾ï¼‰
                        lowmap = {str(k).lower(): k for k in obj.keys()}
                        for k in keys:
                            # ç­–ç•¥1ï¼šç²¾ç¡®åŒ¹é…
                            if k in obj and obj[k]:
                                return obj[k]
                            # ç­–ç•¥2ï¼šå¤§å°å†™ä¸æ•æ„ŸåŒ¹é…
                            lk = k.lower()
                            if lk in lowmap:
                                v = obj.get(lowmap[lk])
                                if v:
                                    return v
                    # ç­–ç•¥3ï¼šåœ¨åµŒå¥—å¯¹è±¡ä¸­æŸ¥æ‰¾ï¼ˆé€’å½’ï¼‰
                    for nest in ('data', 'a', 'novel', 'result'):
                        nested = obj.get(nest) if isinstance(obj, dict) else None
                        if nested:
                            v = pick(nested, *keys)
                            if v:
                                return v
                    # ç­–ç•¥4ï¼šå¦‚æœæ˜¯æ•°ç»„ï¼Œåœ¨ç¬¬ä¸€ä¸ªå…ƒç´ ä¸­æŸ¥æ‰¾
                    if isinstance(obj, list) and obj:
                        return pick(obj[0], *keys)
                except Exception:
                    return ''
                return ''

            # æ­¥éª¤4ï¼šæ„å»ºæ•°æ®æºåˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
            # ä¼˜å…ˆçº§ï¼šotherï¼ˆæ‰©å±•ä¿¡æ¯ï¼‰ > base_dataï¼ˆåŸºç¡€æ•°æ®ï¼‰ > bookï¼ˆå·²æœ‰ä¹¦ç±ä¿¡æ¯ï¼‰
            sources = []
            if isinstance(other, dict):
                sources.append(other)
            if isinstance(base_data, dict):
                sources.append(base_data)
            if isinstance(book, dict):
                sources.append(book)

            # è¾…åŠ©å‡½æ•°ï¼šä»å¤šä¸ªæ•°æ®æºä¸­æŸ¥æ‰¾å­—æ®µå€¼ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
            def pick_any(*keys):
                for src in sources:
                    val = pick(src, *keys)
                    if isinstance(val, str):
                        if val.strip():
                            return val.strip()
                    elif val is not None:
                        return val
                return ''

            # æ­¥éª¤5ï¼šå¼€å§‹æå–å’Œæ ¼å¼åŒ–å„ç§æ‰©å±•ä¿¡æ¯
            lines = []  # ç”¨äºå­˜å‚¨æ ¼å¼åŒ–çš„æè¿°è¡Œ

            # æå–ç•™è¨€/ä½œè€…ç•™è¨€ï¼ˆnovelLeaveï¼‰
            leave_obj = None
            for src in sources:
                if isinstance(src, dict):
                    for k in ('novelLeave', 'leave', 'novelleave'):
                        if k in src and src[k]:
                            leave_obj = src[k]
                            break
                if leave_obj:
                    break
            leave_display = ''
            if leave_obj:
                try:
                    ld_back = leave_obj.get('leaveDateBack') or leave_obj.get('leave_date_back') or ''
                    ld = leave_obj.get('leaveDate') or leave_obj.get('leaveDateStr') or leave_obj.get('leave_date') or ''
                    lcont = leave_obj.get('leaveContent') or leave_obj.get('leave_content') or ''
                    leave_lines = [str(x) for x in (ld_back, lcont, ld) if x]
                    if leave_lines:
                        leave_display = '\n'.join(leave_lines) + '\n&lrm;\n'
                except Exception:
                    leave_display = ''

            # æ–‡ç« ç±»å‹ï¼šåŠ å…¥ lines å¹¶åˆå¹¶åˆ° tags
            novel_class = pick_any('novelClass', 'novel_class', 'category')
            if novel_class:
                try:
                    existing_tags = book.get('tags') or []
                    if not isinstance(existing_tags, list):
                        existing_tags = [t.strip() for t in str(existing_tags).split(',') if t.strip()]
                    merged = [novel_class] + [t for t in existing_tags if str(t).strip() and str(t).strip() != str(novel_class).strip()]
                    seen = set()
                    uniq = []
                    for t in merged:
                        if t and t not in seen:
                            seen.add(t)
                            uniq.append(t)
                    book['tags'] = uniq
                except Exception:
                    book['tags'] = [novel_class]

            # å…¨æ–‡å­—æ•°
            novel_size = pick_any('novelSize', 'novel_size', 'novelSizeShow', 'novelsizeformat', 'word_count', 'words')
            if isinstance(novel_size, (list, dict)):
                try:
                    novel_size = html_to_text(json.dumps(novel_size, ensure_ascii=False))
                except Exception:
                    novel_size = ''

            # éVç‚¹å‡»ã€ç§¯åˆ†
            novip_clicks = pick_any('novip_clicks', 'novipClicks', 'novipClick', 'novipclicks')
            novel_score = pick_any('novelScore', 'score', 'novelscore')

            # ç­¾çº¦çŠ¶æ€ï¼šä»…å½“å­—æ®µå­˜åœ¨æ—¶æ‰å†™å…¥ï¼Œæ”¯æŒå¤šç§è¡¨ç¤ºå½¢å¼ï¼ˆå­—ç¬¦ä¸²æ•°å­—/å¸ƒå°”ï¼‰
            is_sign = pick_any('isSign', 'is_sign', 'issign')
            signed_display = ''
            try:
                if is_sign is not None and str(is_sign).strip() != '':
                    raw_sign = str(is_sign).strip()
                    signed_flag = False
                    if isinstance(is_sign, bool):
                        signed_flag = bool(is_sign)
                    else:
                        lr = raw_sign.lower()
                        if lr in ('1', 'true', 'yes'):
                            signed_flag = True
                        else:
                            try:
                                if re.match(r'^\d+$', raw_sign) and int(raw_sign) > 0:
                                    signed_flag = True
                            except Exception:
                                signed_flag = False
                    signed_display = 'å·²ç­¾çº¦' if signed_flag else 'æœªç­¾çº¦'
                    if log:
                        try:
                            log.debug(f'fetch_and_merge_other_info isSign raw="{raw_sign}" -> {signed_display}')
                        except Exception:
                            pass
            except Exception:
                if log:
                    try:
                        log.debug('Error parsing isSign value')
                    except Exception:
                        pass

            if not signed_display:
                signed_display = 'æœªç­¾çº¦'

            # æ”¶è—/æ’å/è¥å…»
            befav = pick_any('novelbefavoritedcount', 'befavoritedcount', 'favoriteCount')
            nutrition = pick_any('nutrition_novel', 'nutrition', 'nutritionNovel')
            ranking_raw = pick_any('ranking', 'rank', 'ranking_str')
            ranking_number = ''
            if ranking_raw:
                try:
                    m = re.search(r"(\d+)", str(ranking_raw))
                    if m:
                        ranking_number = m.group(1)
                except Exception:
                    ranking_number = ''
            if not befav:
                befav = '0'
            if not ranking_number:
                ranking_number = 'æš‚æ— æ’å'
            nutrition_display = str(nutrition) if nutrition else '0'

            # æ‹“å±•ç®€ä»‹ï¼ˆnovelIntroï¼‰â€”â€”æ˜ å°„åˆ° book['comments']ï¼ŒåŒæ—¶ä¹Ÿä¿ç•™åˆ° lines ä»¥ä¾› description åˆå¹¶
            intro = pick_any('novelIntro', 'novelintro', 'novelIntroShort', 'novelIntroShortHtml', 'description', 'desc')
            if intro:
                intro_txt = html_to_text(str(intro))
                # map to comments (append if exists)
                try:
                    exist_comments = book.get('comments') or ''
                    if exist_comments:
                        book['comments'] = str(exist_comments).strip() + '\n\n' + intro_txt
                    else:
                        book['comments'] = intro_txt
                except Exception:
                    book['comments'] = intro_txt
                intro_txt = intro_txt.replace('ç«‹æ„:', 'ç«‹æ„ï¼š').replace('ç«‹æ„ :', 'ç«‹æ„ï¼š')
            # æ ‡ç­¾ï¼ˆnovelTagsï¼‰â€”â€”åˆå¹¶åˆ° book['tags'] å¹¶åŠ å…¥ lines ä¾›æè¿°ä½¿ç”¨
            tags = pick_any('novelTags', 'novel_tags', 'tags')
            parsed_tags = []
            try:
                if isinstance(tags, str):
                    parsed_tags = [t.strip() for t in re.split(r'[,&/;ï¼Œã€\s]+', tags) if t.strip()]
                elif isinstance(tags, list):
                    parsed_tags = [str(t).strip() for t in tags if str(t).strip()]
            except Exception:
                parsed_tags = []
            tags_line = ''
            if parsed_tags:
                # merge into book['tags'] preserving order and uniqueness
                try:
                    existing_tags = book.get('tags') or []
                    if not isinstance(existing_tags, list):
                        existing_tags = [t.strip() for t in str(existing_tags).split(',') if t.strip()]
                    merged = existing_tags + [t for t in parsed_tags if t not in existing_tags]
                    # dedupe while preserving order
                    seen = set()
                    uniq = []
                    for t in merged:
                        if t and t not in seen:
                            seen.add(t)
                            uniq.append(t)
                    book['tags'] = uniq
                except Exception:
                    book['tags'] = parsed_tags
                tags_line = 'æ ‡ç­¾ï¼š' + '&nbsp;'.join(parsed_tags)

            # ä¸»è§’/é…è§’/å…¶å®ƒ
            prot = pick_any('protagonist', 'protagonists', 'ä¸»è§’')
            costar = pick_any('costar', 'coStar', 'é…è§’')
            other_roles = pick_any('other', 'others')
            role_parts = []
            def clean_role(val):
                if not val:
                    return ''
                txt = html_to_text(str(val))
                return re.sub(r'^(ä¸»è§’|é…è§’|å…¶å®ƒ|å…¶ä»–)[:ï¼š]\s*', '', txt)
            prot_clean = clean_role(prot)
            costar_clean = clean_role(costar)
            other_clean = clean_role(other_roles)
            if prot_clean:
                role_parts.append(f'ä¸»è§’ï¼š{prot_clean}')
            if costar_clean:
                role_parts.append(f'é…è§’ï¼š{costar_clean}')
            if other_clean:
                role_parts.append(f'å…¶å®ƒï¼š{other_clean}')
            roles_comb = ''.join(role_parts)

            # é£æ ¼/è§†è§’/ç³»åˆ—ï¼ˆä¿æŒä¸å‚è€ƒæ¨¡æ¿ä¸€è‡´çš„å¸ƒå±€ï¼‰
            style = pick_any('novelStyle', 'style')
            mainview = pick_any('mainview', 'view')
            series = pick_any('series')
            style_line = f"é£æ ¼ï¼š{style or ''}&nbsp;&nbsp;&nbsp;&nbsp;è§†è§’ï¼š{mainview or ''}" if (style or mainview) else ''
            series_line = f'æ‰€å±ï¼š{series}' if series else ''

            # æ„å»ºæœ€ç»ˆæè¿°å—ï¼Œå‚è€ƒæä¾›çš„æ¨¡æ¿
            first_line = (leave_display or '') + (f"æ–‡ç« ç±»å‹ï¼š{novel_class}" if novel_class else '')
            if first_line:
                lines.append(first_line)
            elif leave_display:
                lines.append(leave_display.rstrip('\n'))

            if novel_size:
                lines.append(f'å…¨æ–‡å­—æ•°ï¼š{novel_size}')
            if novip_clicks:
                lines.append(f'éVç‚¹å‡»ï¼š{novip_clicks}')
            if novel_score:
                lines.append(f'æ–‡ç« ç§¯åˆ†ï¼š{novel_score}')
            if signed_display:
                lines.append(f'ç­¾çº¦çŠ¶æ€ï¼š{signed_display}')

            lines.append('&lrm;')
            lines.append(f'â­&nbsp;{befav}ä¸¨ğŸ‘&nbsp;No.{ranking_number}ä¸¨ğŸ¼&nbsp;{nutrition_display}')
            lines.append('&lrm;')

            if intro and intro_txt:
                lines.append(intro_txt)
                lines.append('&lrm;')

            if tags_line:
                lines.append(tags_line)
            if roles_comb:
                lines.append(roles_comb)
            if style_line:
                lines.append(style_line)
            if series_line:
                lines.append(series_line)

            # ç§»é™¤åŸå…ˆæ³¨å…¥åˆ°æè¿°ä¸­çš„å‰ç«¯ JS å¤„ç†æç¤ºï¼Œé¿å…åœ¨ Calibre ç®€ä»‹ä¸­å‡ºç°æ‚é¡¹æ–‡æœ¬

            # æŠŠ lines åˆå¹¶åˆ° description å­—æ®µï¼ˆHTML + çº¯æ–‡æœ¬ï¼‰
            if lines:
                extra_html = '<br>'.join([str(x).replace('\n', '<br>') for x in lines])
                extra_text = '\n'.join([str(x) for x in lines])
                # åˆå¹¶åˆ°å·²æœ‰ç®€ä»‹
                try:
                    exist_html = book.get('description_html') or book.get('description') or ''
                    if exist_html:
                        book['description_html'] = str(exist_html) + '<br><br>' + extra_html
                    else:
                        book['description_html'] = extra_html
                except Exception:
                    book['description_html'] = extra_html
                try:
                    exist_txt = book.get('description') or ''
                    if exist_txt:
                        book['description'] = str(exist_txt) + '\n\n' + extra_text
                    else:
                        book['description'] = extra_text
                except Exception:
                    book['description'] = extra_text

        except Exception as e:
            if log:
                try:
                    log.debug(f'fetch_and_merge_other_info error: {e}')
                except Exception:
                    pass
            return


    def load_book_via_app_api(self, novelid, log):
        """
        é€šè¿‡ APP è¯¦æƒ…æ¥å£è·å–ä¹¦ç±æ•°æ®ï¼ˆå¤šç«¯å…¼å®¹ï¼‰
        
        æœ¬æ–¹æ³•å°è¯•å¤šä¸ªå·²çŸ¥çš„ APP è¯¦æƒ…æ¥å£ï¼Œä½¿ç”¨ä¸åŒçš„å‚æ•°åå˜ä½“ï¼Œä»¥å…¼å®¹ä¸åŒçš„æ¥å£ç‰ˆæœ¬ã€‚
        å¦‚æœæŸä¸ªæ¥å£è¿”å›å¯ç”¨çš„ JSON æ•°æ®ï¼Œåˆ™è§£æå¹¶è¿”å›ä¹¦ç±ä¿¡æ¯å­—å…¸ï¼Œå¦åˆ™è¿”å› Noneã€‚
        
        å°è¯•ç­–ç•¥ï¼š
        1. å°è¯•å¤šä¸ªæ¥å£ç«¯ç‚¹ï¼ˆCDNã€ä¸»ç«™ç­‰ï¼‰
        2. å¯¹æ¯ä¸ªç«¯ç‚¹ï¼Œå°è¯•ä¸åŒçš„å‚æ•°åï¼ˆnovelidã€novelIdã€bookIdã€bookidï¼‰
        3. å…¼å®¹ä¸åŒçš„ JSON è¿”å›ç»“æ„ï¼ˆcode/data å°è£…ã€ç›´æ¥å¯¹è±¡ã€æ•°ç»„ç­‰ï¼‰
        4. éªŒè¯è§£æç»“æœçš„å…³é”®å­—æ®µï¼ˆtitleã€authorsï¼‰ï¼Œç¼ºå¤±åˆ™è§†ä¸ºå¤±è´¥
        
        Args:
            novelid: ä¹¦ç± ID
            log: æ—¥å¿—è®°å½•å™¨å¯¹è±¡
            
        Returns:
            ä¹¦ç±ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœæ‰€æœ‰æ¥å£éƒ½å¤±è´¥åˆ™è¿”å› None
        """
        # å€™é€‰æ¥å£ç«¯ç‚¹åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        # ä¼˜å…ˆå°è¯• CDN ç«¯ç‚¹ï¼ˆé€šå¸¸æ›´å¿«ï¼‰ï¼Œç„¶åå›é€€åˆ°ä¸»ç«™ç«¯ç‚¹
        detail_endpoints = [
            'https://app-cdn.jjwxc.net/androidapi/novelbasicinfo',  # CDN ç«¯ç‚¹ï¼ˆæ¨èï¼‰
            JINJIANG_BOOK_DETAIL_APP_URL,  # æ ‡å‡† APP è¯¦æƒ…æ¥å£
            'https://app.jjwxc.org/androidapi/novelbasicinfo'  # å¤‡é€‰ç«¯ç‚¹
        ]

        # é…ç½® SSL ä¸Šä¸‹æ–‡ï¼šç¦ç”¨éªŒè¯ä»¥é¿å…æœ¬åœ°è¯ä¹¦é—®é¢˜
        ctx = ssl.create_default_context()
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE

        tried = []  # è®°å½•å°è¯•è¿‡çš„ URLï¼Œç”¨äºè°ƒè¯•

        # å‚æ•°åå˜ä½“åˆ—è¡¨ï¼ˆä¸åŒæ¥å£å¯èƒ½ä½¿ç”¨ä¸åŒçš„å‚æ•°åï¼‰
        param_variants = [
            {'novelid': novelid},   # å°å†™
            {'novelId': novelid},  # é©¼å³°
            {'bookId': novelid},   # bookId æ ¼å¼
            {'bookid': novelid}    # å…¨å°å†™ bookid
        ]

        # éå†æ‰€æœ‰ç«¯ç‚¹å’Œå‚æ•°å˜ä½“ç»„åˆ
        for endpoint in detail_endpoints:
            for base_params in param_variants:
                params = dict(base_params)
                # å¦‚æœå­˜åœ¨ sidï¼Œæ·»åŠ  token å‚æ•°ï¼ˆç”¨äºèº«ä»½éªŒè¯ï¼‰
                if self.sid:
                    params['token'] = self.sid
                # æ·»åŠ å®¢æˆ·ç«¯ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿ APP è¯·æ±‚ï¼‰
                params.setdefault('version', '9.9.9')
                params.setdefault('platform', 'android')

                url = endpoint + '?' + urlencode(params)
                tried.append(url)
                try:
                    log.debug(f'Trying APP detail URL: {url}')
                    res = urlopen(Request(url, headers=self.get_headers(), method='GET'), timeout=15, context=ctx)
                    if res.status not in (200, 201):
                        continue
                    content = self.get_res_content(res)
                    # try parse JSON
                    try:
                        data = json.loads(content)
                    except Exception:
                        data = None

                    if not data:
                        # some endpoints may return directly the object or wrap under 'data' or 'items'
                        try:
                            # attempt to find JSON-like substring
                            j = json.loads(content.strip())
                            data = j
                        except Exception:
                            data = None

                    if data:
                        # common patterns: { code:0, data: { ... } } or { data: { book: ... } } or { items: [...] }
                        app_data = None
                        if isinstance(data, dict):
                            if data.get('code') == 0 and data.get('data'):
                                d = data.get('data')
                                # if 'book' key present inside data, use it
                                if isinstance(d, dict) and (d.get('book') or d.get('novel')):
                                    app_data = d.get('book') or d.get('novel') or d
                                else:
                                    app_data = d
                            elif data.get('data') and isinstance(data.get('data'), dict):
                                app_data = data.get('data')
                            elif data.get('items'):
                                # items list - pick first item that matches novelid
                                items = data.get('items')
                                if isinstance(items, list) and items:
                                    # find matching item by novelid/bookId if present
                                    found = None
                                    for it in items:
                                        try:
                                            if str(it.get('novelid') or it.get('bookId') or it.get('id')) == str(novelid):
                                                found = it
                                                break
                                        except Exception:
                                            continue
                                    app_data = found or items[0]
                            else:
                                # sometimes the top-level dict is already the book data
                                app_data = data
                        elif isinstance(data, list) and data:
                            # list of books
                            app_data = data[0]

                        if app_data:
                            try:
                                parsed = self.parse_app_book_data(app_data, novelid, log)
                                # éªŒè¯è§£æç»“æœï¼šè‹¥å…³é”®å­—æ®µç¼ºå¤±ï¼ˆä¹¦å/ä½œè€…ï¼‰ï¼Œè§†ä¸ºè§£æå¤±è´¥ä»¥è§¦å‘å›é€€
                                title_ok = bool(parsed.get('title'))
                                authors_ok = bool(parsed.get('authors'))
                                if not title_ok or not authors_ok:
                                    log.debug(f'APP detail parsed but missing title/authors for {novelid}, will fallback to web')
                                else:
                                    return parsed
                            except Exception as e:
                                log.debug(f'parse_app_book_data failed: {e}')
                except Exception as e:
                    log.debug(f'APP detail request to {url} failed: {e}')

        log.debug(f'Tried APP detail URLs: {tried}')
        return None

    def parse_app_book_data(self, app_data, novelid, log=None):
        """
        è§£æ APP æ¥å£è¿”å›çš„ JSON æ•°æ®
        
        æœ¬æ–¹æ³•å…·æœ‰å¼ºå¤§çš„å…¼å®¹æ€§ï¼Œèƒ½å¤Ÿå¤„ç†ä¸åŒç‰ˆæœ¬çš„ API è¿”å›æ ¼å¼ï¼š
        - æ”¯æŒå¤šç§é”®åå˜ä½“ï¼ˆé©¼å³°ã€ä¸‹åˆ’çº¿ã€å¤§å°å†™ç­‰ï¼‰
        - æ”¯æŒåœ¨åµŒå¥—å­—æ®µä¸­æŸ¥æ‰¾ï¼ˆbook/novel/data/items[0] ç­‰ï¼‰
        - è‡ªåŠ¨æ¸…æ´— HTML æ ‡ç­¾ï¼Œæå–çº¯æ–‡æœ¬
        - å½“å…³é”®å­—æ®µç¼ºå¤±æ—¶ï¼Œå°è¯•å°†åŸå§‹ JSON ä¿å­˜åˆ°æ¡Œé¢ debug æ–‡ä»¶ï¼ˆä¾¿äºæ’æŸ¥é—®é¢˜ï¼‰
        
        è§£æçš„å­—æ®µåŒ…æ‹¬ï¼š
        - åŸºæœ¬ä¿¡æ¯ï¼štitleã€authorsã€coverã€description
        - å…ƒæ•°æ®ï¼štagsã€publishedDateã€statusã€word_countã€chapters
        - æ‰©å±•ä¿¡æ¯ï¼šé€šè¿‡ fetch_and_merge_other_info æ–¹æ³•è¡¥å……
        
        Args:
            app_data: APP æ¥å£è¿”å›çš„ JSON æ•°æ®ï¼ˆå­—å…¸æˆ–åˆ—è¡¨ï¼‰
            novelid: ä¹¦ç± ID
            log: æ—¥å¿—è®°å½•å™¨å¯¹è±¡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ä¹¦ç±ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰è§£æå‡ºçš„å­—æ®µ
        """
        book = {}
        book['id'] = novelid

        # ç”Ÿæˆå€™é€‰ key å˜ä½“
        def key_variants(k):
            vs = set()
            if not k:
                return vs
            vs.add(k)
            vs.add(k.lower())
            # é©¼å³°/ä¸‹åˆ’çº¿äº’è½¬
            vs.add(''.join([p.capitalize() if i>0 else p for i,p in enumerate(k.split('_'))]))
            vs.add(k.replace('_', ''))
            vs.add(k.replace('_', '').lower())
            vs.add(k.replace(' ', ''))
            # å¸¸è§é©¼å³°å°å†™é¦–å­—æ¯
            if '_' in k:
                parts = k.split('_')
                camel = parts[0] + ''.join([p.capitalize() for p in parts[1:]])
                vs.add(camel)
            return vs

        # ä»ä¸€ä¸ª dict ä¸­é€’å½’æŸ¥æ‰¾é¦–ä¸ªéç©ºå€¼ï¼ˆåªå‘ä¸‹ä¸€å±‚åµŒå¥—å¯»æ‰¾ï¼‰
        def _pick_from(obj, *keys):
            if not obj or not keys:
                return ''
            # å…ˆå°è¯•ç›´æ¥æˆ–å˜ä½“é”®
            try:
                for k in keys:
                    for cand in key_variants(k):
                        if isinstance(obj, dict) and cand in obj and obj[cand]:
                            return obj[cand]
                # å†å°è¯•ä¸ç²¾ç¡®åŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
                if isinstance(obj, dict):
                    lowmap = {str(kk).lower(): kk for kk in obj.keys()}
                    for k in keys:
                        lk = k.lower()
                        if lk in lowmap:
                            v = obj.get(lowmap[lk])
                            if v:
                                return v
            except Exception:
                pass
            # å¦‚æœæœªæ‰¾åˆ°ï¼Œå°è¯•åœ¨å¸¸è§åµŒå¥—å­—æ®µä¸­å¯»æ‰¾ï¼ˆbook/novel/data/items first elementï¼‰
            for nest_key in ('book', 'novel', 'data', 'result'):
                try:
                    nested = obj.get(nest_key)
                except Exception:
                    nested = None
                if isinstance(nested, dict):
                    v = _pick_from(nested, *keys)
                    if v:
                        return v
                elif isinstance(nested, list) and nested:
                    v = _pick_from(nested[0], *keys)
                    if v:
                        return v
            # æœ€åï¼Œå¦‚æœ obj æœ¬èº«æ˜¯åˆ—è¡¨ï¼Œå°è¯•ç¬¬ä¸€é¡¹
            if isinstance(obj, list) and obj:
                try:
                    return _pick_from(obj[0], *keys)
                except Exception:
                    pass
            return ''

        # title: å°è¯•å¤§é‡å€™é€‰é”®
        title_candidates = ('bookname', 'bookName', 'book_name', 'novelname', 'novelName', 'name', 'title', 'novelname_format', 'novelname_format_html')
        title = _pick_from(app_data, *title_candidates) or ''
        if isinstance(title, (list, dict)):
            title = str(title)
        title = html_to_text(str(title))
        book['title'] = title.strip()

        # authors: å°è¯•æ›´å¤šé”®åå’ŒåµŒå¥—
        author_candidates = ('authorname', 'author', 'authorName', 'authors', 'writer', 'writerName', 'author_name', 'authorNames')
        author_field = _pick_from(app_data, *author_candidates) or ''
        if isinstance(author_field, (list, dict)):
            # å¦‚æœæ˜¯ listï¼Œå°è¯• join æˆ–å–ç¬¬ä¸€ä¸ª
            if isinstance(author_field, list) and author_field:
                author_str = ','.join([html_to_text(str(x)) for x in author_field])
            else:
                author_str = html_to_text(json.dumps(author_field, ensure_ascii=False))
        else:
            author_str = html_to_text(str(author_field))

        # åˆ†å‰²ä½œè€…å­—ç¬¦ä¸²ï¼ˆå…¼å®¹ä¸­æ–‡åˆ†å‰²ç¬¦ï¼‰
        authors = [a.strip() for a in re.split(r'[,&/;ï¼Œã€\s]+', author_str) if a.strip()]
        book['authors'] = authors
        book['url'] = JINJIANG_BOOK_DETAIL_WEB_URL % novelid

        # å°é¢ï¼šä¼˜å…ˆä½¿ç”¨ novelCover å’Œ originalCoverï¼ˆçœŸå®å°é¢ï¼‰ï¼Œé¿å…ä½¿ç”¨ localImgï¼ˆé»˜è®¤å°é¢ï¼‰
        # ä¼˜å…ˆçº§ï¼šnovelCover > originalCover > å…¶ä»–å­—æ®µ > localImgï¼ˆæœ€åå¤‡é€‰ï¼‰
        cover = _pick_from(app_data, 'novelCover') or ''
        if not cover:
            cover = _pick_from(app_data, 'originalCover') or ''
        if not cover:
            cover_candidates = ('coverimg', 'cover', 'cover_img', 'bookimg', 'coverUrl', 'cover_url')
            cover = _pick_from(app_data, *cover_candidates) or ''
        # æœ€åæ‰å°è¯• localImgï¼ˆé€šå¸¸æ˜¯é»˜è®¤å°é¢ï¼‰
        if not cover:
            cover = _pick_from(app_data, 'localImg') or ''
        cover = str(cover).strip()
        if cover:
            if cover.startswith('//'):
                cover = 'https:' + cover
            elif cover.startswith('/'):
                cover = JINJIANG_BASE_URL.rstrip('/') + cover
            elif not cover.startswith('http://') and not cover.startswith('https://') and not cover.startswith('data:'):
                # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ä½†æ²¡æœ‰å‰å¯¼æ–œæ ï¼Œå°è¯•æ„å»ºå®Œæ•´URL
                if cover:
                    cover = JINJIANG_BASE_URL.rstrip('/') + '/' + cover.lstrip('/')
        # éªŒè¯URLæœ‰æ•ˆæ€§ï¼šåªä¿ç•™æœ‰æ•ˆçš„HTTP/HTTPS URLæˆ–data URI
        book['cover'] = cover if cover and (cover.startswith('http://') or cover.startswith('https://') or cover.startswith('data:')) else ''

        # ç®€ä»‹
        intro_candidates = ('intro', 'novelintroshort', 'novelintro', 'description', 'desc')
        intro_html = _pick_from(app_data, *intro_candidates) or ''
        book['description_html'] = str(intro_html).strip()
        book['description'] = html_to_text(str(intro_html))

        # æ ‡ç­¾
        category = _pick_from(app_data, 'category') or ''
        tags_raw = _pick_from(app_data, 'tags') or ''
        tags = []
        try:
            if isinstance(tags_raw, str):
                tags = [t.strip() for t in tags_raw.split(',') if t.strip()]
            elif isinstance(tags_raw, list):
                tags = [str(t).strip() for t in tags_raw if str(t).strip()]
        except Exception:
            tags = []
        if category:
            tags.insert(0, category)
        book['tags'] = tags

        # createtime -> publishedDate
        createtime = _pick_from(app_data, 'createtime', 'createTime', 'publish_time') or ''
        createtime = str(createtime).strip()
        published = ''
        try:
            if createtime.isdigit():
                ts = int(createtime)
                if ts > 1e12:
                    ts = ts / 1000
                published = datetime.fromtimestamp(ts).strftime('%Y-%m-%d')
            else:
                m = re.match(r"^(\d{4})[-/å¹´]?(\d{1,2})?[-/æœˆ]?(\d{1,2})?", createtime)
                if m:
                    y = m.group(1)
                    mo = m.group(2) or '01'
                    d = m.group(3) or '01'
                    published = f"{y}-{int(mo):02d}-{int(d):02d}"
                else:
                    published = createtime
        except Exception:
            published = createtime
        book['publishedDate'] = published

        book['status'] = _pick_from(app_data, 'status') or ''
        book['word_count'] = _pick_from(app_data, 'wordcount', 'wordCount') or 0

        try:
            book['chapters'] = int(_pick_from(app_data, 'chapterCount', 'chaptercount', 'chapters') or 0)
        except Exception:
            book['chapters'] = None
        try:
            book['vip_start'] = int(_pick_from(app_data, 'vip_start', 'vipStart', 'vipstart') or 0)
        except Exception:
            book['vip_start'] = None

        book['source'] = {
            "id": PROVIDER_ID,
            "description": PROVIDER_NAME,
            "link": JINJIANG_BASE_URL
        }

        # å°è¯•æ‹‰å–å¹¶åˆå¹¶æ¥è‡ª getnovelOtherInfo çš„æ‰©å±•ä¿¡æ¯ï¼ˆç•™è¨€ã€ç±»å‹ã€æ ‡ç­¾ç­‰ï¼‰
        try:
            try:
                # é€šè¿‡å•ç‹¬æ–¹æ³•è¯·æ±‚å¹¶åˆå¹¶é¢å¤–ä¿¡æ¯
                self.fetch_and_merge_other_info(novelid, book, log, base_data=app_data)
            except Exception:
                # ä¸åº”é˜»å¡ä¸»æµç¨‹ï¼Œæ—¥å¿—è°ƒè¯•å³å¯
                if log:
                    log.debug('fetch_and_merge_other_info failed')
        except Exception:
            pass

        # è‹¥å…³é”®å­—æ®µç¼ºå¤±ï¼Œä»…è®°å½•åˆ°æ—¥å¿—ï¼ˆä¸å†å†™å…¥æ¡Œé¢æ–‡ä»¶ï¼‰
        if (not book['title'] or not book['authors']) and log:
            try:
                # ä»…è®°å½•JSONç‰‡æ®µåˆ°æ—¥å¿—ï¼Œä¸å†™å…¥æ–‡ä»¶
                snippet = json.dumps(app_data, ensure_ascii=False)[:2000]
                log.warning(f'APPè§£ææœªæå–åˆ° title/authorï¼ŒåŸå§‹ JSON ç‰‡æ®µ: {snippet}')
            except Exception:
                pass

        return book

    def get_res_content(self, res):
        """
        å¤„ç† HTTP å“åº”å†…å®¹
        
        å¤„ç†æ­¥éª¤ï¼š
        1. æ£€æŸ¥å“åº”æ˜¯å¦ä½¿ç”¨ gzip å‹ç¼©ï¼Œå¦‚æœæ˜¯åˆ™è§£å‹
        2. æ£€æµ‹å­—ç¬¦ç¼–ç ï¼ˆä»å“åº”å¤´è·å–ï¼Œé»˜è®¤ä½¿ç”¨ UTF-8ï¼‰
        3. è§£ç å“åº”å†…å®¹ä¸ºå­—ç¬¦ä¸²
        
        Args:
            res: urllib çš„ HTTPResponse å¯¹è±¡
            
        Returns:
            è§£ç åçš„å“åº”å†…å®¹å­—ç¬¦ä¸²
        """
        # æ£€æŸ¥å“åº”æ˜¯å¦ä½¿ç”¨ gzip å‹ç¼©
        encoding = res.info().get('Content-Encoding')
        if encoding == 'gzip':
            res_content = gzip.decompress(res.read())
        else:
            res_content = res.read()
        
        # æ£€æµ‹å­—ç¬¦ç¼–ç ï¼ˆä»å“åº”å¤´è·å–ï¼Œé»˜è®¤ä½¿ç”¨ UTF-8ï¼‰
        charset = res.headers.get_content_charset() or 'utf-8'
        
        # è§£ç å“åº”å†…å®¹ï¼Œå¿½ç•¥æ— æ³•è§£ç çš„å­—ç¬¦ï¼ˆé¿å…è§£ç é”™è¯¯å¯¼è‡´ç¨‹åºå´©æºƒï¼‰
        return res_content.decode(charset, errors='ignore')

    def get_headers(self):
        """
        ç”Ÿæˆå¢å¼ºçš„ HTTP è¯·æ±‚å¤´ï¼ˆæ¨¡æ‹Ÿ APP/ç§»åŠ¨ç«¯ï¼‰
        
        è¯·æ±‚å¤´ç‰¹ç‚¹ï¼š
        - éšæœº User-Agentï¼ˆ50% æ¦‚ç‡ä½¿ç”¨ Calibre çš„éšæœº UAï¼Œ50% ä½¿ç”¨æ™‹æ±Ÿ APP UAï¼‰
        - æ”¯æŒ gzip å‹ç¼©
        - è®¾ç½®åˆé€‚çš„ Accept å¤´
        - å¦‚æœé…ç½®äº†ç™»å½• Cookieï¼Œè‡ªåŠ¨æ·»åŠ åˆ°è¯·æ±‚å¤´ä¸­
        
        Returns:
            åŒ…å«æ‰€æœ‰å¿…è¦è¯·æ±‚å¤´çš„å­—å…¸
        """
        headers = {
            # User-Agentï¼š50% æ¦‚ç‡ä½¿ç”¨ Calibre éšæœº UAï¼Œ50% ä½¿ç”¨æ™‹æ±Ÿ APP UAï¼ˆæ¨¡æ‹Ÿç§»åŠ¨ç«¯ï¼‰
            'User-Agent': random_user_agent() if random.random() > 0.5 else 'JJWXC-Android/9.9.9 (Android; 10; SM-G973F)',
            'Accept-Encoding': 'gzip, deflate, br',  # æ”¯æŒå‹ç¼©ä¼ è¾“
            'Accept': 'application/json, text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            # Refererï¼šæ ¹æ®æ˜¯å¦ä¼˜å…ˆä½¿ç”¨ APP API è®¾ç½®ä¸åŒçš„æ¥æºé¡µ
            'Referer': JINJIANG_M_BASE_URL if self.jinjiang_prefer_app_api else JINJIANG_BASE_URL,
            'Connection': 'keep-alive',  # ä¿æŒè¿æ¥
            'X-Requested-With': 'XMLHttpRequest'  # æ ‡è¯†ä¸º AJAX è¯·æ±‚
        }
        # å¦‚æœé…ç½®äº†ç™»å½• Cookieï¼Œæ·»åŠ åˆ°è¯·æ±‚å¤´ä¸­
        if self.jinjiang_login_cookie:
            headers['Cookie'] = self.jinjiang_login_cookie
        return headers

    def random_sleep(self, log):
        """
        æ‰§è¡Œéšæœºå»¶è¿Ÿï¼ˆç”¨äºé¿å…è§¦å‘åçˆ¬è™«æœºåˆ¶ï¼‰
        
        å»¶è¿Ÿæ—¶é—´æ ¹æ®ä½¿ç”¨çš„æ¥å£ç±»å‹è°ƒæ•´ï¼š
        - APP æ¥å£ï¼š0.2-0.8 ç§’ï¼ˆåçˆ¬è™«æœºåˆ¶è¾ƒå¼±ï¼Œå¯ä»¥è¾ƒçŸ­å»¶è¿Ÿï¼‰
        - ç½‘é¡µæ¥å£ï¼š0.5-1.8 ç§’ï¼ˆåçˆ¬è™«æœºåˆ¶è¾ƒå¼ºï¼Œéœ€è¦è¾ƒé•¿å»¶è¿Ÿï¼‰
        
        Args:
            log: æ—¥å¿—è®°å½•å™¨å¯¹è±¡ï¼ˆç”¨äºè®°å½•å»¶è¿Ÿæ—¶é—´ï¼‰
        """
        if self.jinjiang_prefer_app_api:
            random_sec = random.uniform(0.2, 0.8)  # APP æ¥å£å»¶è¿Ÿè¾ƒçŸ­ï¼ˆåçˆ¬è™«æœºåˆ¶è¾ƒå¼±ï¼‰
        else:
            random_sec = random.uniform(0.5, 1.8)  # ç½‘é¡µæ¥å£å»¶è¿Ÿè¾ƒé•¿ï¼ˆåçˆ¬è™«æœºåˆ¶è¾ƒå¼ºï¼‰
        log.info(f'Random sleep: {random_sec:.2f}s')
        time.sleep(random_sec)


class JinjiangBookHtmlParser:
    """
    ç½‘é¡µè¯¦æƒ…é¡µ HTML è§£æå™¨ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
    
    å½“ APP æ¥å£å¤±è´¥æ—¶ï¼Œä½¿ç”¨æ­¤è§£æå™¨ä»ç½‘é¡µ HTML ä¸­æå–ä¹¦ç±ä¿¡æ¯ã€‚
    ä½¿ç”¨ lxml åº“è§£æ HTMLï¼Œé€šè¿‡ XPath é€‰æ‹©å™¨æå–å„ç§å­—æ®µã€‚
    """
    def __init__(self):
        self.novelid_pattern = re.compile(r"novelid=(\d+)")

    def parse_book(self, url, book_content, log):
        book = {}
        html = etree.HTML(book_content)
        if not html:
            return None

        # ä¹¦ç±ID
        id_match = self.novelid_pattern.search(url)
        book['id'] = id_match.group(1) if id_match else None
        if not book['id']:
            return None

        # ä¹¦å
        title_elements = html.xpath("//h1[contains(@class, 'bookname')] | //div[contains(@class, 'novelname')]/h1")
        book['title'] = self.get_text(title_elements).strip()
        if not book['title']:
            return None

        # ä½œè€…
        author_elements = html.xpath("//a[contains(@class, 'author')] | //div[contains(@class, 'authorinfo')]//a[contains(@href, 'authorid')]")
        book['authors'] = [self.get_text(author_elements).strip()] if author_elements else []

        # å°é¢
        img_elements = html.xpath("//div[contains(@class, 'bookimg')]//img | //div[contains(@class, 'novelimg')]//img")
        book['cover'] = ''
        if img_elements:
            cover_src = img_elements[0].attrib.get('src', '').strip()
            if cover_src:
                if cover_src.startswith('//'):
                    cover_src = 'https:' + cover_src
                elif cover_src.startswith('/'):
                    cover_src = JINJIANG_BASE_URL.rstrip('/') + cover_src
                elif not cover_src.startswith('http://') and not cover_src.startswith('https://'):
                    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•æ„å»ºå®Œæ•´URL
                    if not cover_src.startswith('data:'):
                        cover_src = JINJIANG_BASE_URL.rstrip('/') + '/' + cover_src.lstrip('/')
                # éªŒè¯URLæœ‰æ•ˆæ€§
                if cover_src and (cover_src.startswith('http://') or cover_src.startswith('https://') or cover_src.startswith('data:')):
                    book['cover'] = cover_src

        # ç®€ä»‹
        summary_elements = html.xpath("//div[contains(@class, 'intro')] | //div[@id='novelintro']")
        book['description'] = self.get_text(summary_elements, join_lines=True)

        # æ ‡ç­¾
        tag_elements = html.xpath("//div[contains(@class, 'tag')]//a | //div[contains(@class, 'classify')]//a")
        book['tags'] = [self.get_text([elem]).strip() for elem in tag_elements if self.get_text([elem]).strip()]

        # å‡ºç‰ˆæ—¶é—´
        pubdate_elements = html.xpath("//div[contains(@class, 'infobox')]//span[contains(text(), 'è¿è½½æ—¶é—´') or contains(text(), 'å‘è¡¨æ—¶é—´')]")
        book['publishedDate'] = self.get_tail(pubdate_elements)

        # æ¥æºä¿¡æ¯
        book['url'] = url
        book['source'] = {
            "id": PROVIDER_ID,
            "description": PROVIDER_NAME,
            "link": JINJIANG_BASE_URL
        }

        return book

    def get_text(self, elements, default_str='', join_lines=False):
        texts = []
        for elem in elements:
            if isinstance(elem, etree._Element):
                text = ' '.join(elem.xpath('.//text()')).strip()
                if text:
                    texts.append(text)
        if join_lines:
            return '\n'.join(texts) if texts else default_str
        return texts[0] if texts else default_str

    def get_tail(self, elements, default_str=''):
        for elem in elements:
            if isinstance(elem, etree._Element) and elem.tail:
                tail_text = elem.tail.strip()
                if tail_text:
                    return tail_text
            next_elem = elem.getnext()
            if next_elem:
                next_text = self.get_text([next_elem]).strip()
                if next_text:
                    return next_text
        return default_str


class NewJinjiangBooks(Source):
    """
    æ™‹æ±Ÿæ–‡å­¦åŸå…ƒæ•°æ®æ’ä»¶ä¸»ç±»
    
    è¿™æ˜¯ Calibre å…ƒæ•°æ®æºæ’ä»¶ï¼Œç»§æ‰¿è‡ª Source åŸºç±»ã€‚
    æä¾›ä»æ™‹æ±Ÿæ–‡å­¦åŸè·å–ä¹¦ç±å…ƒæ•°æ®çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬è¯†åˆ«ä¹¦ç±å’Œä¸‹è½½å°é¢ã€‚
    
    ä¸»è¦åŠŸèƒ½ï¼š
    - identify: æ ¹æ®ä¹¦å/ä½œè€…æœç´¢å¹¶è¯†åˆ«ä¹¦ç±
    - cover: ä¸‹è½½ä¹¦ç±å°é¢å›¾ç‰‡
    
    æ”¯æŒçš„å¹³å°ï¼šWindowsã€macOSã€Linux
    æœ€ä½ Calibre ç‰ˆæœ¬è¦æ±‚ï¼š5.0.0
    """
    name = PROVIDER_NAME
    description = 'Enhanced Jinjiang Books Plugin (supports APP API, multi-type search) - æ”¯æŒå¤šç±»å‹æœç´¢ã€APPæ¥å£'
    supported_platforms = ['windows', 'osx', 'linux']
    author = PROVIDER_AUTHOR
    version = PROVIDER_VERSION
    minimum_calibre_version = (5, 0, 0)
    capabilities = frozenset(['identify', 'cover'])  # æ’ä»¶èƒ½åŠ›ï¼šè¯†åˆ«å’Œå°é¢ä¸‹è½½
    
    # touched_fields: å£°æ˜æ’ä»¶ä¼šä¿®æ”¹çš„ Calibre å…ƒæ•°æ®å­—æ®µ
    # æ³¨æ„ï¼šåªå£°æ˜ Calibre æ ‡å‡†æ”¯æŒçš„å­—æ®µï¼Œéæ ‡å‡†å­—æ®µï¼ˆå¦‚ status/word_countï¼‰ä¸åº”æ”¾å…¥æ­¤åˆ—è¡¨
    touched_fields = frozenset([
        'title', 'authors', 'tags', 'pubdate', 'comments', 'identifier:isbn',
        'rating', 'identifier:' + PROVIDER_ID, 'publisher'
    ])
    book_searcher = None  # ä¹¦ç±æœç´¢å™¨å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰

    options = (
        Option(
            'jinjiang_concurrency_size', 'number', JINJIANG_CONCURRENCY_SIZE,
            _('Concurrency size:'),
            _('Maximum number of concurrent requests (â‰¤5 recommended)')
        ),
        Option(
            'jinjiang_delay_enable', 'bool', True,
            _('Enable random delay:'),
            _('Avoid anti-crawling (required for web search)')
        ),
        Option(
            'jinjiang_login_cookie', 'string', None,
            _('Login cookie:'),
            _('Cookie after logging into Jinjiang (required for APP API and VIP content)')
        ),
        Option(
            'jinjiang_search_with_author', 'bool', False,
            _('Search with author:'),
            _('Add author name to search keywords (improve accuracy)')
        ),
        Option(
            'jinjiang_prefer_app_api', 'bool', True,
            _('Prefer APP API:'),
            _('Use APP API first (more stable, less anti-crawling)')
        ),
    )

    def __init__(self, *args, **kwargs):
        """
        åˆå§‹åŒ–æ’ä»¶
        
        ä» Calibre é…ç½®ä¸­è¯»å–ç”¨æˆ·è®¾ç½®çš„é€‰é¡¹ï¼Œå¹¶åˆå§‹åŒ–ä¹¦ç±æœç´¢å™¨ã€‚
        """
        Source.__init__(self, *args, **kwargs)
        
        # ä» Calibre é…ç½®ä¸­è¯»å–ç”¨æˆ·é€‰é¡¹
        concurrency_size = int(self.prefs.get('jinjiang_concurrency_size', JINJIANG_CONCURRENCY_SIZE))
        jinjiang_delay_enable = bool(self.prefs.get('jinjiang_delay_enable', True))
        jinjiang_login_cookie = self.prefs.get('jinjiang_login_cookie', None)
        jinjiang_search_with_author = bool(self.prefs.get('jinjiang_search_with_author', False))
        jinjiang_prefer_app_api = bool(self.prefs.get('jinjiang_prefer_app_api', True))
        
        # åˆå§‹åŒ–ä¹¦ç±æœç´¢å™¨ï¼Œä¼ å…¥æ‰€æœ‰é…ç½®é€‰é¡¹
        self.book_searcher = JinjiangBookSearcher(
            concurrency_size=concurrency_size,
            jinjiang_delay_enable=jinjiang_delay_enable,
            jinjiang_login_cookie=jinjiang_login_cookie,
            jinjiang_search_with_author=jinjiang_search_with_author,
            jinjiang_prefer_app_api=jinjiang_prefer_app_api
        )

    def get_book_url(self, identifiers):
        """
        ä»æ ‡è¯†ç¬¦ä¸­è·å–ä¹¦ç± URL
        
        Args:
            identifiers: Calibre æ ‡è¯†ç¬¦å­—å…¸
            
        Returns:
            å¦‚æœæ‰¾åˆ°æ™‹æ±Ÿ IDï¼Œè¿”å› (provider_id, book_id, url) å…ƒç»„ï¼Œå¦åˆ™è¿”å› None
        """
        jinjiang_id = identifiers.get(PROVIDER_ID, None)
        if jinjiang_id:
            return PROVIDER_ID, jinjiang_id, JINJIANG_BOOK_DETAIL_WEB_URL % jinjiang_id
        return None

    def identify(self, log, result_queue, abort, title=None, authors=None, identifiers={}, timeout=30):
        """
        Calibre è¯†åˆ«æ¥å£ï¼šæ ¹æ®ä¹¦å/ä½œè€…æœç´¢å¹¶è¯†åˆ«ä¹¦ç±
        
        è¯†åˆ«ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
        1. å¦‚æœæä¾›äº†ä¹¦ç± IDï¼Œç›´æ¥é€šè¿‡ ID åŠ è½½
        2. å¦‚æœæä¾›äº†ä¹¦åï¼Œä½¿ç”¨ä¹¦åæœç´¢ï¼ˆå¯èƒ½åŒ…å«ä½œè€…åï¼‰
        3. å¦‚æœä¹¦åæœç´¢æ— ç»“æœï¼Œå°è¯•ä»…æŒ‰ä½œè€…æœç´¢
        4. å¦‚æœä»æ— ç»“æœï¼Œç”Ÿæˆä¹¦åå˜ä½“å¹¶é‡è¯•
        
        æ‰€æœ‰æ‰¾åˆ°çš„ä¹¦ç±éƒ½ä¼šè¢«è½¬æ¢ä¸º Calibre Metadata å¯¹è±¡å¹¶æ”¾å…¥ç»“æœé˜Ÿåˆ—ã€‚
        
        Args:
            log: æ—¥å¿—è®°å½•å™¨å¯¹è±¡
            result_queue: ç»“æœé˜Ÿåˆ—ï¼ˆç”¨äºè¿”å›è¯†åˆ«åˆ°çš„ä¹¦ç±å…ƒæ•°æ®ï¼‰
            abort: ä¸­æ­¢ä¿¡å·ï¼ˆç”¨äºæ”¯æŒç”¨æˆ·å–æ¶ˆæ“ä½œï¼‰
            title: ä¹¦ç±æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
            authors: ä½œè€…åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            identifiers: ä¹¦ç±æ ‡è¯†ç¬¦å­—å…¸ï¼ˆå¯é€‰ï¼Œå¦‚æœåŒ…å«æ™‹æ±Ÿ ID åˆ™ç›´æ¥ä½¿ç”¨ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        log.info(f'Jinjiang identify: title={title}, authors={authors}, identifiers={identifiers}')

        # ç­–ç•¥1ï¼šä¼˜å…ˆé€šè¿‡ ID æŸ¥è¯¢ï¼ˆæœ€å¿«é€Ÿã€æœ€å‡†ç¡®ï¼‰
        book_url_info = self.get_book_url(identifiers)
        if book_url_info:
            provider_id, book_id, url = book_url_info
            log.info(f'Query by ID: {book_id}')
            book = self.book_searcher.load_book(url, log)
            books = [book] if book else []
        else:
            # ç­–ç•¥2ï¼šé€šè¿‡ä¹¦å/ä½œè€…æœç´¢
            if not title and not authors:
                log.warning('No title or authors provided')
                return

            # æ­¥éª¤1ï¼šæ¸…æ´—å¹¶è§„èŒƒåŒ–æŸ¥è¯¢è¯ï¼ˆæé«˜æœç´¢åŒ¹é…ç‡ï¼‰
            cleaned_title = normalize_query(title) if title else ''
            cleaned_authors = [normalize_query(a) for a in authors] if authors else []

            # æ­¥éª¤2ï¼šä½¿ç”¨ä¹¦åï¼ˆå¯èƒ½åŒ…å«ä½œè€…ï¼‰è¿›è¡Œæœç´¢
            t0 = time.time()
            books = self.book_searcher.search_books(query=cleaned_title or ' '.join(cleaned_authors), authors=authors, log=log)
            elapsed = time.time() - t0
            log.info(f'Found {len(books)} results from Jinjiang (time: {elapsed:.3f}s)')

            # æ­¥éª¤3ï¼šå¦‚æœä¹¦åæœç´¢æ— ç»“æœï¼Œå°è¯•ä»…æŒ‰ä½œè€…æœç´¢
            # ä½¿ç”¨æ™‹æ±Ÿçš„ JSON è§„åˆ™ï¼š#ä½œè€…# è¡¨ç¤ºæŒ‰ä½œè€…æœç´¢
            if not books and cleaned_authors:
                t1 = time.time()
                author_query = ' '.join(cleaned_authors)
                wrapped = f"#{author_query}#"
                log.info(f'No results for title-search, retrying with author-only (wrapped): {wrapped}')
                books = self.book_searcher.search_books(query=wrapped, authors=authors, log=log)
                elapsed2 = time.time() - t1
                log.info(f'Author-only search found {len(books)} results (time: {elapsed2:.3f}s)')

            # æ­¥éª¤4ï¼šå¦‚æœä»æ— ç»“æœï¼Œç”Ÿæˆä¹¦åå˜ä½“å¹¶é‡è¯•
            # å˜ä½“åŒ…æ‹¬ï¼šå»é™¤æ ‡æ³¨è¯ï¼ˆå¦‚"å®Œç»“"ã€"ç•ªå¤–"ï¼‰ã€æå–å…³é”®è¯ç­‰
            if not books and cleaned_title:
                variations = generate_title_variations(cleaned_title)
                for var in variations:
                    t2 = time.time()
                    log.info(f'Trying title variation: {var}')
                    books = self.book_searcher.search_books(query=var, authors=authors, log=log)
                    elapsed3 = time.time() - t2
                    log.info(f'Variation {var} found {len(books)} results (time: {elapsed3:.3f}s)')
                    if books:
                        break

        for book in books:
            if abort.is_set():
                break
            if book:
                metadata = self.to_metadata(book, log)
                if isinstance(metadata, Metadata):
                    # cache cover url if present
                    try:
                        dbid = metadata.identifiers.get(PROVIDER_ID)
                        if metadata.cover and dbid:
                            try:
                                # store cover URL mapping so Calibre can download later
                                self.cache_identifier_to_cover_url(dbid, metadata.cover)
                            except Exception:
                                log.debug('cache_identifier_to_cover_url failed')
                    except Exception:
                        pass

                    # allow Calibre to clean/normalize the metadata before returning
                    try:
                        self.clean_downloaded_metadata(metadata)
                    except Exception:
                        log.debug('clean_downloaded_metadata failed')

                    result_queue.put(metadata)

    # browse èƒ½åŠ›å·²ç§»é™¤ä»¥ç®€åŒ–æ’ä»¶ä¸ºä»…æŒ‰ä¹¦å/ä½œè€…æå–å…ƒæ•°æ®

    def to_metadata(self, book, log):
        mi = Metadata(book['title'], book['authors'])
        mi.identifiers = {PROVIDER_ID: book['id']}
        mi.url = book['url']
        # å°é¢ï¼šä¿ç•™å°é¢ URL åˆ° mi.coverï¼ˆCalibre æ¥å— URL å­—ç¬¦ä¸²ï¼‰å¹¶ç¼“å­˜ URL ä¾› download_cover ä½¿ç”¨
        mi.cover = book.get('cover', None)
        if mi.cover:
            try:
                self.cache_identifier_to_cover_url(book['id'], mi.cover)
            except Exception:
                log.debug('Cache cover URL failed')
        
        # ç®€ä»‹ï¼ˆå·²è½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼‰
        mi.comments = book.get('description', '') or book.get('description_html', '')
        
        # æ ‡ç­¾
        if book.get('tags'):
            mi.tags = book['tags']
        
        # å‡ºç‰ˆæ—¥æœŸ
        pubdate_str = book.get('publishedDate')
        if pubdate_str:
            try:
                pubdate_str = pubdate_str.replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
                if re.match(r'^\d{4}-\d{2}-\d{2}$', pubdate_str):
                    mi.pubdate = datetime.strptime(pubdate_str, '%Y-%m-%d')
                elif re.match(r'^\d{4}-\d{2}$', pubdate_str):
                    mi.pubdate = datetime.strptime(pubdate_str, '%Y-%m')
                elif re.match(r'^\d{4}$', pubdate_str):
                    mi.pubdate = datetime.strptime(pubdate_str, '%Y')
            except Exception as e:
                log.warning(f'Parse pubdate failed: {e}')
        
        # æ–°å¢å­—æ®µï¼ˆæ¥è‡ªAPPæ¥å£ï¼‰
        mi.set('status', book.get('status', ''))  # è¿è½½çŠ¶æ€
        mi.set('word_count', book.get('word_count', 0))  # å­—æ•°
        # ä¿ç•™åŸå§‹ HTML ç®€ä»‹ä»¥ä¾¿éœ€è¦æ—¶ä½¿ç”¨
        if book.get('description_html'):
            mi.set('description_html', book.get('description_html'))
        # ç« èŠ‚ä¸ VIP ä¿¡æ¯
        if book.get('chapters') is not None:
            mi.set('chapters', book.get('chapters'))
        if book.get('vip_start') is not None:
            mi.set('vip_start', book.get('vip_start'))
        # è¯­è¨€
        try:
            mi.language = 'zh_CN'
        except Exception:
            try:
                mi.set('language', 'zh_CN')
            except Exception:
                log.debug('Failed to set language')
        # è¯„åˆ†ï¼ˆè‹¥å­˜åœ¨ï¼‰
        if book.get('rating') is not None:
            try:
                mi.rating = float(book.get('rating'))
            except Exception:
                pass
        # ISBN/Seriesï¼ˆå ä½ï¼Œå¦‚æœè¿”å›å†å†™å…¥ï¼‰
        if book.get('isbn'):
            try:
                mi.isbn = book.get('isbn')
            except Exception:
                pass
        if book.get('series'):
            try:
                mi.series = book.get('series')
            except Exception:
                pass
        
        mi.source = book['source']['description']
        # å¦‚æœå…ƒæ•°æ®æ¥è‡ªæ™‹æ±Ÿ APP/ç½‘é¡µï¼Œåˆ™ç»Ÿä¸€è®¾ç½®å‡ºç‰ˆç¤¾ä¸ºâ€œæ™‹æ±Ÿæ–‡å­¦åŸâ€
        try:
            mi.publisher = 'æ™‹æ±Ÿæ–‡å­¦åŸ'
        except Exception:
            try:
                mi.set('publisher', 'æ™‹æ±Ÿæ–‡å­¦åŸ')
            except Exception:
                log.debug('Failed to set publisher field')
        return mi

    def download_cover(self, log, result_queue, abort, title=None, authors=None, identifiers={}, timeout=30, get_best_cover=False):
        cached_url = self.get_cached_cover_url(identifiers)
        if not cached_url:
            log.info('No cached cover, run identify first')
            rq = Queue()
            self.identify(log, rq, abort, title=title, authors=authors, identifiers=identifiers)
            if abort.is_set():
                return
            
            results = []
            while True:
                try:
                    results.append(rq.get_nowait())
                except Empty:
                    break
            
            for mi in results:
                cached_url = self.get_cached_cover_url(mi.identifiers)
                if cached_url:
                    break
        
        if not cached_url:
            log.info('No cover found')
            return
        
        log.info(f'Download cover: {cached_url}')
        try:
            br = self.browser
            if self.book_searcher.jinjiang_login_cookie:
                br = br.clone_browser()
                br.set_current_header('Cookie', self.book_searcher.jinjiang_login_cookie)
            br.set_current_header('Referer', JINJIANG_BASE_URL)
            br.set_current_header('User-Agent', random_user_agent())
            
            cdata = br.open_novisit(cached_url, timeout=timeout).read()
            if cdata:
                result_queue.put((self, cdata))
        except Exception as e:
            log.error(f'Download cover failed: {e}')

    def get_cached_cover_url(self, identifiers):
        jinjiang_id = identifiers.get(PROVIDER_ID)
        if not jinjiang_id:
            return None
        return self.cached_identifier_to_cover_url(jinjiang_id)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    try:
        from calibre.ebooks.metadata.sources.test import test_identify_plugin, title_test, authors_test
    except Exception:
        # Calibre test harness not available in this environment; skip local tests
        print('Calibre test harness not available, skipping tests')
    else:
        test_identify_plugin(
            NewJinjiangBooks.name,
            [
                (
                    {
                        'title': '#é…±å­è´#',  # ä½œè€…æœç´¢ï¼ˆJSONè§„åˆ™ï¼‰
                        'authors': [],
                        'identifiers': {}
                    },
                    [
                        title_test('æˆ‘è¡Œè®©æˆ‘ä¸Š[ç”µç«]', exact=False),
                        authors_test(['é…±å­è´'])
                    ]
                ),
                (
                    {
                        'title': 'æˆ‘å–œæ¬¢ä½ çš„ä¿¡æ¯ç´ ',
                        'authors': ['å¼•è·¯æ˜Ÿ'],
                        'identifiers': {}
                    },
                    [
                        title_test('æˆ‘å–œæ¬¢ä½ çš„ä¿¡æ¯ç´ ', exact=True),
                        authors_test(['å¼•è·¯æ˜Ÿ'])
                    ]
                )
            ]
        )